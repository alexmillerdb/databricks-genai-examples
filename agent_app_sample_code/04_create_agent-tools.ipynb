{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31661828-f9bb-4fc2-a1bd-94424a27ed52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üëâ START HERE: How to use this notebook\n",
    "\n",
    "# Step 3: Build, evaluate, & deploy your Agent\n",
    "\n",
    "Use this notebook to iterate on the code and configuration of your Agent.\n",
    "\n",
    "By the end of this notebook, you will have 1+ registered versions of your Agent, each coupled with a detailed quality evaluation.\n",
    "\n",
    "Optionally, you can deploy a version of your Agent that you can interact with in the [Mosiac AI Playground](https://docs.databricks.com/en/large-language-models/ai-playground.html) and let your business stakeholders who don't have Databricks accounts interact with it & provide feedback in the [Review App](https://docs.databricks.com/en/generative-ai/agent-evaluation/human-evaluation.html#review-app-ui).\n",
    "\n",
    "\n",
    "For each version of your agent, you will have an MLflow run inside your MLflow experiment that contains:\n",
    "- Your Agent's code & config\n",
    "- Evaluation metrics for cost, quality, and latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d9f685a-fdb7-49a4-9e3a-a4a9e964d045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Important note:** Throughout this notebook, we indicate which cell's code you:\n",
    "- ‚úÖ‚úèÔ∏è should customize - these cells contain code & config with business logic that you should edit to meet your requirements & tune quality.\n",
    "- üö´‚úèÔ∏è should not customize - these cells contain boilerplate code required to load/save/execute your Agent\n",
    "\n",
    "*Cells that don't require customization still need to be run!  You CAN change these cells, but if this is the first time using this notebook, we suggest not doing so.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb4f8cc0-1797-4beb-a9f2-df21a9db79f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üö´‚úèÔ∏è Install Python libraries\n",
    "\n",
    "You do not need to modify this cell unless you need additional Python packages in your Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d4030e8-ae97-4351-bebd-9651d283578f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install -qqqq -U -r requirements.txt\n",
    "# # Restart to load the packages into the Python environment\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üö´‚úèÔ∏è Connect to Databricks\n",
    "\n",
    "If running locally in an IDE using Databricks Connect, connect the Spark client & configure MLflow to use Databricks Managed MLflow.  If this running in a Databricks Notebook, these values are already set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.utils import databricks_utils as du\n",
    "\n",
    "if not du.is_in_databricks_notebook():\n",
    "    from databricks.connect import DatabricksSession\n",
    "    import os\n",
    "\n",
    "    spark = DatabricksSession.builder.getOrCreate()\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = \"databricks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üö´‚úèÔ∏è Load the Agent's UC storage locations; set up MLflow experiment\n",
    "\n",
    "This notebook uses the UC model, MLflow Experiment, and Evaluation Set that you specified in the [Agent setup](02_agent_setup.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"uc_model_name\": \"ep.cookbook_local_test.my_agent\",\n",
      "  \"evaluation_set_uc_table\": \"ep.cookbook_local_test.my_agent_eval_set\",\n",
      "  \"mlflow_experiment_name\": \"/Users/eric.peter@databricks.com/my_agent_mlflow_experiment\",\n",
      "  \"class_path\": \"cookbook.config.shared.agent_storage_location.AgentStorageConfig\"\n",
      "}\n",
      "View the MLflow Experiment `/Users/eric.peter@databricks.com/my_agent_mlflow_experiment` at https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/3916415516852775\n"
     ]
    }
   ],
   "source": [
    "from cookbook.config.shared.agent_storage_location import AgentStorageConfig\n",
    "from cookbook.databricks_utils import get_mlflow_experiment_url\n",
    "from cookbook.config import load_serializable_config_from_yaml_file\n",
    "import mlflow \n",
    "\n",
    "# Load the Agent's storage locations\n",
    "agent_storage_config: AgentStorageConfig= load_serializable_config_from_yaml_file(\"./configs/agent_storage_config.yaml\")\n",
    "\n",
    "# Show the Agent's storage locations\n",
    "agent_storage_config.pretty_print()\n",
    "\n",
    "# set the MLflow experiment\n",
    "experiment_info = mlflow.set_experiment(agent_storage_config.mlflow_experiment_name)\n",
    "# If running in a local IDE, set the MLflow experiment name as an environment variable\n",
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = agent_storage_config.mlflow_experiment_name\n",
    "\n",
    "print(f\"View the MLflow Experiment `{agent_storage_config.mlflow_experiment_name}` at {get_mlflow_experiment_url(experiment_info.experiment_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üö´‚úèÔ∏è Helper method to log the Agent's code & config to MLflow\n",
    "\n",
    "Before we start, let's define a helper method to log the Agent's code & config to MLflow.  We will use this to log the agent's code & config to MLflow & the Unity Catalog.  It is used in evaluation & for deploying to Agent Evaluation's [Review App](https://docs.databricks.com/en/generative-ai/agent-evaluation/human-evaluation.html#review-app-ui) (a chat UI for your stakeholders to test this agent) and later, deplying the Agent to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "from mlflow.types.llm import CHAT_MODEL_INPUT_SCHEMA\n",
    "from mlflow.models.rag_signatures import StringResponse\n",
    "from cookbook.agents.utils.signatures import STRING_RESPONSE_WITH_MESSAGES\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from cookbook.agents.function_calling_agent import FunctionCallingAgent\n",
    "from cookbook.agents.function_calling_agent import FunctionCallingAgentConfig\n",
    "\n",
    "# This helper will log the Agent's code & config to an MLflow run and return the logged model's URI\n",
    "# If run from inside a mlfow.start_run() block, it will log to that run, otherwise it will log to a new run.\n",
    "# This logged Agent is ready for deployment, so if you are happy with your evaluation, it is ready to deploy!\n",
    "def log_agent_to_mlflow(agent_config: FunctionCallingAgentConfig):\n",
    "    # Get the agent's code path from the imported Agent class\n",
    "    agent_code_path = f\"{os.getcwd()}/{FunctionCallingAgent.__module__.replace('.', '/')}.py\"\n",
    "\n",
    "    # Get the pip requirements from the requirements.txt file\n",
    "    with open(\"requirements.txt\", \"r\") as file:\n",
    "        pip_requirements = [line.strip() for line in file.readlines()] + [\"pyspark\"] # manually add pyspark\n",
    "\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"agent\",\n",
    "            python_model=agent_code_path,\n",
    "            input_example=agent_config.input_example,\n",
    "            model_config=agent_config.model_dump(),\n",
    "            resources=agent_config.get_resource_dependencies(), # This allows the agents.deploy() command to securely provision credentials for the Agent's databricks resources e.g., vector index, model serving endpoints, etc\n",
    "            signature=ModelSignature(\n",
    "            inputs=CHAT_MODEL_INPUT_SCHEMA,\n",
    "            # outputs=STRING_RESPONSE_WITH_MESSAGES #TODO: replace with MLflow signature\n",
    "            outputs=StringResponse()\n",
    "        ),\n",
    "        code_paths=[os.path.join(os.getcwd(), \"cookbook\")],\n",
    "        pip_requirements=pip_requirements,\n",
    "    )\n",
    "\n",
    "    return logged_agent_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create tools\n",
    "\n",
    "- we will store all tools in the `user_tools` folder\n",
    "- first, create a local function & test it with pytest\n",
    "- then, deploy it as a UC tool & test it with pytest\n",
    "- then, add the tool to the Agent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "always reload the tool's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "talk about the need for google doc string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tools/sample_tool.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tools/sample_tool.py\n",
    "\n",
    "def sku_sample_translator(old_sku: str) -> str:\n",
    "    \"\"\"\n",
    "    Translates a pre-2024 SKU formatted as \"OLD-XXX-YYYY\" to the new SKU format \"NEW-YYYY-XXX\".\n",
    "\n",
    "    Args:\n",
    "        old_sku (str): The old SKU in the format \"OLD-XXX-YYYY\".\n",
    "\n",
    "    Returns:\n",
    "        str: The new SKU in the format \"NEW-YYYY-XXX\".\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the SKU format is invalid, providing specific error details.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    if not isinstance(old_sku, str):\n",
    "        raise ValueError(\"SKU must be a string\")\n",
    "\n",
    "    # Normalize input by removing extra whitespace and converting to uppercase\n",
    "    old_sku = old_sku.strip().upper()\n",
    "\n",
    "    # Define the regex pattern for the old SKU format\n",
    "    pattern = r\"^OLD-([A-Z]{3})-(\\d{4})$\"\n",
    "\n",
    "    # Match the old SKU against the pattern\n",
    "    match = re.match(pattern, old_sku)\n",
    "    if not match:\n",
    "        if not old_sku.startswith(\"OLD-\"):\n",
    "            raise ValueError(\"SKU must start with 'OLD-'\")\n",
    "        if not re.match(r\"^OLD-[A-Z]{3}-\\d{4}$\", old_sku):\n",
    "            raise ValueError(\n",
    "                \"SKU format must be 'OLD-XXX-YYYY' where X is a letter and Y is a digit\"\n",
    "            )\n",
    "        raise ValueError(\"Invalid SKU format\")\n",
    "\n",
    "    # Extract the letter code and numeric part\n",
    "    letter_code, numeric_part = match.groups()\n",
    "\n",
    "    # Additional validation for numeric part\n",
    "    if not (1 <= int(numeric_part) <= 9999):\n",
    "        raise ValueError(\"Numeric part must be between 0001 and 9999\")\n",
    "\n",
    "    # Construct the new SKU\n",
    "    new_sku = f\"NEW-{numeric_part}-{letter_code}\"\n",
    "    return new_sku\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import the tool and test it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEW-1234-XXX'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.sample_tool import sku_sample_translator\n",
    "\n",
    "sku_sample_translator(\"OLD-XXX-1234\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, lets write some pyTest unit tests for the tool - these are just samples, you will need to write your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tools/test_sample_tool.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tools/test_sample_tool.py\n",
    "import pytest\n",
    "from tools.sample_tool import sku_sample_translator\n",
    "\n",
    "\n",
    "\n",
    "def test_valid_sku_translation():\n",
    "    \"\"\"Test successful SKU translation with valid input.\"\"\"\n",
    "    assert sku_sample_translator(\"OLD-ABC-1234\") == \"NEW-1234-ABC\"\n",
    "    assert sku_sample_translator(\"OLD-XYZ-0001\") == \"NEW-0001-XYZ\"\n",
    "    assert sku_sample_translator(\"old-def-5678\") == \"NEW-5678-DEF\"  # Test case insensitivity\n",
    "\n",
    "\n",
    "def test_whitespace_handling():\n",
    "    \"\"\"Test that the function handles extra whitespace correctly.\"\"\"\n",
    "    assert sku_sample_translator(\"  OLD-ABC-1234  \") == \"NEW-1234-ABC\"\n",
    "    assert sku_sample_translator(\"\\tOLD-ABC-1234\\n\") == \"NEW-1234-ABC\"\n",
    "\n",
    "\n",
    "def test_invalid_input_type():\n",
    "    \"\"\"Test that non-string inputs raise ValueError.\"\"\"\n",
    "    with pytest.raises(ValueError, match=\"SKU must be a string\"):\n",
    "        sku_sample_translator(123)\n",
    "    with pytest.raises(ValueError, match=\"SKU must be a string\"):\n",
    "        sku_sample_translator(None)\n",
    "\n",
    "\n",
    "def test_invalid_prefix():\n",
    "    \"\"\"Test that SKUs not starting with 'OLD-' raise ValueError.\"\"\"\n",
    "    with pytest.raises(ValueError, match=\"SKU must start with 'OLD-'\"):\n",
    "        sku_sample_translator(\"NEW-ABC-1234\")\n",
    "    with pytest.raises(ValueError, match=\"SKU must start with 'OLD-'\"):\n",
    "        sku_sample_translator(\"XXX-ABC-1234\")\n",
    "\n",
    "\n",
    "def test_invalid_format():\n",
    "    \"\"\"Test various invalid SKU formats.\"\"\"\n",
    "    invalid_skus = [\n",
    "        \"OLD-AB-1234\",  # Too few letters\n",
    "        \"OLD-ABCD-1234\",  # Too many letters\n",
    "        \"OLD-123-1234\",  # Numbers instead of letters\n",
    "        \"OLD-ABC-123\",  # Too few digits\n",
    "        \"OLD-ABC-12345\",  # Too many digits\n",
    "        \"OLD-ABC-XXXX\",  # Letters instead of numbers\n",
    "        \"OLD-A1C-1234\",  # Mixed letters and numbers in middle\n",
    "    ]\n",
    "\n",
    "    for sku in invalid_skus:\n",
    "        with pytest.raises(\n",
    "            ValueError,\n",
    "            match=\"SKU format must be 'OLD-XXX-YYYY' where X is a letter and Y is a digit\",\n",
    "        ):\n",
    "            sku_sample_translator(sku)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, lets run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.10, pytest-8.3.3, pluggy-1.5.0 -- /Users/eric.peter/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/eric.peter/Github/genai-cookbook/agent_app_sample_code\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.6.2.post1, typeguard-4.3.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 5 items\n",
      "\n",
      "tools/test_sample_tool.py::test_valid_sku_translation \u001b[32mPASSED\u001b[0m\u001b[32m             [ 20%]\u001b[0m\n",
      "tools/test_sample_tool.py::test_whitespace_handling \u001b[32mPASSED\u001b[0m\u001b[32m               [ 40%]\u001b[0m\n",
      "tools/test_sample_tool.py::test_invalid_input_type \u001b[32mPASSED\u001b[0m\u001b[32m                [ 60%]\u001b[0m\n",
      "tools/test_sample_tool.py::test_invalid_prefix \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 80%]\u001b[0m\n",
      "tools/test_sample_tool.py::test_invalid_format \u001b[32mPASSED\u001b[0m\u001b[32m                    [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytest\n",
    "\n",
    "# Run tests from test_sku_translator.py\n",
    "pytest.main([\"-v\", \"tools/test_sample_tool.py\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets deploy the tool to Unity catalog & wrap it into a UCTool that will be used by our Agent.  UC tool is just a Pydnatic base model that is serializable to YAML that will load the tool's metadata from UC and wrap it in a callable object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed Unity Catalog function name: ep.cookbook_local_test.sku_sample_translator\n"
     ]
    }
   ],
   "source": [
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "from tools.sample_tool import sku_sample_translator\n",
    "from cookbook.tools.uc_tool import UCTool\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "CATALOG = \"ep\"  # Change me!\n",
    "SCHEMA = \"cookbook_local_test\"  # Change me if you want\n",
    "\n",
    "# this will deploy the tool to UC, automatically setting the metadata in UC based on the tool's docstring & typing hints\n",
    "tool_uc_info = client.create_python_function(func=sku_sample_translator, catalog=CATALOG, schema=SCHEMA, replace=True)\n",
    "\n",
    "# the tool will deploy to a function in UC called `{catalog}.{schema}.{func}` where {func} is the name of the function\n",
    "# Print the deployed Unity Catalog function name\n",
    "print(f\"Deployed Unity Catalog function name: {tool_uc_info.full_name}\")\n",
    "\n",
    "# wrap the tool into a UCTool which can be passed to our Agent\n",
    "translate_sku_tool = UCTool(uc_function_name=tool_uc_info.full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test the UC tool - the UCTool is a directly callable wrapper around the UC function, so it can be used just like a local function, but the output will be put into a dictionary with either the output in a 'value' key or an 'error' key if an error is raised.\n",
    "\n",
    "when an error happens, the UC tool will also return an instruction prompt to show the agent how to think about handling the error.  this can be changed via the `error_prompt` parameter in the UCTool..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': None, 'format': 'SCALAR', 'value': 'NEW-1234-XXX', 'truncated': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# successful call\n",
    "translate_sku_tool(old_sku=\"OLD-XXX-1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error parsing: 'stack', trying alternative approaches to parsing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'error': {'stack_trace': 'line 17, in main\\n    raise ValueError(\"SKU must start with \\'OLD-\\'\")',\n",
       "  'error_message': \"ValueError: SKU must start with 'OLD-'\"},\n",
       " 'error_instructions': 'The tool call generated an Exception, detailed in `error`. Think step-by-step following these instructions to determine your next step.\\n[1] Is the error due to a problem with the input parameters?\\n[2] Could it succeed if retried with exactly the same inputs?\\n[3] Could it succeed if retried with modified parameters using the input we already have from the user?\\n[4] Could it succeed if retried with modified parameters informed by collecting additional input from the user?  What specific input would we need from the user?\\nBased on your thinking, if the error is due to a problem with the input parameters, either call this tool again in a way that avoids this exception or collect additional information from the user to modify the inputs to avoid this exception.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unsuccessful call\n",
    "translate_sku_tool(old_sku=\"OxxLD-XXX-1234\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, let's convert our pytests to work with the UC tool.  this requires a bit of transformation to the test code, so we will use a helper method to do this.  see example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tools/test_sample_tool_uc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tools/test_sample_tool_uc.py\n",
    "import pytest\n",
    "from cookbook.tools.uc_tool import UCTool\n",
    "\n",
    "\n",
    "# Load the function from the UCTool versus locally\n",
    "@pytest.fixture\n",
    "def uc_tool():\n",
    "    \"\"\"Fixture to translate a UC tool into a local function.\"\"\"\n",
    "    UC_FUNCTION_NAME = \"ep.cookbook_local_test.sku_sample_translator\"\n",
    "    loaded_tool = UCTool(uc_function_name=UC_FUNCTION_NAME)\n",
    "    return loaded_tool\n",
    "\n",
    "\n",
    "# Note: The value will be post processed into the `value` key, so we must check the returned value there.\n",
    "def test_valid_sku_translation(uc_tool):\n",
    "    \"\"\"Test successful SKU translation with valid input.\"\"\"\n",
    "    assert uc_tool(old_sku=\"OLD-ABC-1234\")[\"value\"] == \"NEW-1234-ABC\"\n",
    "    assert uc_tool(old_sku=\"OLD-XYZ-0001\")[\"value\"] == \"NEW-0001-XYZ\"\n",
    "    assert (\n",
    "        uc_tool(old_sku=\"old-def-5678\")[\"value\"] == \"NEW-5678-DEF\"\n",
    "    )  # Test case insensitivity\n",
    "\n",
    "\n",
    "# Note: The value will be post processed into the `value` key, so we must check the returned value there.\n",
    "def test_whitespace_handling(uc_tool):\n",
    "    \"\"\"Test that the function handles extra whitespace correctly.\"\"\"\n",
    "    assert uc_tool(old_sku=\"  OLD-ABC-1234  \")[\"value\"] == \"NEW-1234-ABC\"\n",
    "    assert uc_tool(old_sku=\"\\tOLD-ABC-1234\\n\")[\"value\"] == \"NEW-1234-ABC\"\n",
    "\n",
    "\n",
    "# Note: the input validation happens BEFORE the function is called by Spark, so we will never get these exceptions from the function.\n",
    "# Instead, we will get invalid parameters errors from Spark.\n",
    "def test_invalid_input_type(uc_tool):\n",
    "    \"\"\"Test that non-string inputs raise ValueError.\"\"\"\n",
    "    assert (\n",
    "        uc_tool(old_sku=123)[\"error\"][\"error_message\"]\n",
    "        == \"\"\"Invalid parameters provided: {'old_sku': \"Parameter old_sku should be of type STRING (corresponding python type <class 'str'>), but got <class 'int'>\"}.\"\"\"\n",
    "    )\n",
    "    assert (\n",
    "        uc_tool(old_sku=None)[\"error\"][\"error_message\"]\n",
    "        == \"\"\"Invalid parameters provided: {'old_sku': \"Parameter old_sku should be of type STRING (corresponding python type <class 'str'>), but got <class 'NoneType'>\"}.\"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Note: The errors will be post processed into the `error_message` key inside the `error` top level key, so we must check for exceptions there.\n",
    "def test_invalid_prefix(uc_tool):\n",
    "    \"\"\"Test that SKUs not starting with 'OLD-' raise ValueError.\"\"\"\n",
    "    assert (\n",
    "        uc_tool(old_sku=\"NEW-ABC-1234\")[\"error\"][\"error_message\"]\n",
    "        == \"ValueError: SKU must start with 'OLD-'\"\n",
    "    )\n",
    "    assert (\n",
    "        uc_tool(old_sku=\"XXX-ABC-1234\")[\"error\"][\"error_message\"]\n",
    "        == \"ValueError: SKU must start with 'OLD-'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Note: The errors will be post processed into the `error_message` key inside the `error` top level key, so we must check for exceptions there.\n",
    "def test_invalid_format(uc_tool):\n",
    "    \"\"\"Test various invalid SKU formats.\"\"\"\n",
    "    invalid_skus = [\n",
    "        \"OLD-AB-1234\",  # Too few letters\n",
    "        \"OLD-ABCD-1234\",  # Too many letters\n",
    "        \"OLD-123-1234\",  # Numbers instead of letters\n",
    "        \"OLD-ABC-123\",  # Too few digits\n",
    "        \"OLD-ABC-12345\",  # Too many digits\n",
    "        \"OLD-ABC-XXXX\",  # Letters instead of numbers\n",
    "        \"OLD-A1C-1234\",  # Mixed letters and numbers in middle\n",
    "    ]\n",
    "\n",
    "    expected_error = \"ValueError: SKU format must be 'OLD-XXX-YYYY' where X is a letter and Y is a digit\"\n",
    "    for sku in invalid_skus:\n",
    "        assert uc_tool(old_sku=sku)[\"error\"][\"error_message\"] == expected_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.10, pytest-8.3.3, pluggy-1.5.0 -- /Users/eric.peter/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/eric.peter/Github/genai-cookbook/agent_app_sample_code\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.6.2.post1, typeguard-4.3.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 5 items\n",
      "\n",
      "tools/test_sample_tool_uc.py::test_valid_sku_translation \u001b[32mPASSED\u001b[0m\u001b[32m          [ 20%]\u001b[0m\n",
      "tools/test_sample_tool_uc.py::test_whitespace_handling \u001b[32mPASSED\u001b[0m\u001b[32m            [ 40%]\u001b[0m\n",
      "tools/test_sample_tool_uc.py::test_invalid_input_type \u001b[32mPASSED\u001b[0m\u001b[32m             [ 60%]\u001b[0m\n",
      "tools/test_sample_tool_uc.py::test_invalid_prefix "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error parsing: 'stack', trying alternative approaches to parsing.\n",
      "ERROR:root:Error parsing: 'stack', trying alternative approaches to parsing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mPASSED\u001b[0m\u001b[32m                 [ 80%]\u001b[0m\n",
      "tools/test_sample_tool_uc.py::test_invalid_format "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error parsing: 'stack', trying alternative approaches to parsing.\n",
      "ERROR:root:Error parsing: 'stack', trying alternative approaches to parsing.\n",
      "ERROR:root:Error parsing: 'stack', trying alternative approaches to parsing.\n",
      "ERROR:root:Error parsing: 'stack', trying alternative approaches to parsing.\n",
      "ERROR:root:Error parsing: 'stack', trying alternative approaches to parsing.\n",
      "ERROR:root:Error parsing: 'stack', trying alternative approaches to parsing.\n",
      "ERROR:root:Error parsing: 'stack', trying alternative approaches to parsing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mPASSED\u001b[0m\u001b[32m                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 202.33s (0:03:22)\u001b[0m\u001b[32m =========================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytest\n",
    "\n",
    "# Run tests from test_sku_translator.py\n",
    "pytest.main([\"-v\", \"tools/test_sample_tool_uc.py\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9933d05f-29fa-452e-abdc-2a02328fbe22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 1Ô∏è‚É£ Iterate on the Agent's code & config to improve quality\n",
    "\n",
    "The below cells are used to execute your inner dev loop to improve the Agent's quality.\n",
    "\n",
    "We suggest the following process:\n",
    "1. Vibe check the Agent for 5 - 10 queries to verify it works\n",
    "2. Make any necessary changes to the code/config\n",
    "3. Use Agent Evaluation to evaluate the Agent using your evaluation set, which will provide a quality assessment & identify the root causes of any quality issues\n",
    "4. Based on that evaluation, make & test changes to the code/config to improve quality\n",
    "5. üîÅ Repeat steps 3 and 4 until you are satisified with the Agent's quality\n",
    "6. Deploy the Agent to Agent Evaluation's [Review App](https://docs.databricks.com/en/generative-ai/agent-evaluation/human-evaluation.html#review-app-ui) for pre-production testing\n",
    "7. Use the following notebooks to review that feedback (optionally adding new records to your evaluation set) & identify any further quality issues\n",
    "8. üîÅ Repeat steps 3 and 4 to fix any issues identified in step 7\n",
    "9. Deploy the Agent to a production-ready REST API endpoint (using the same cells in this notebook as step 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionInfo(browse_only=None, catalog_name='ep', comment='Translates a pre-2024 SKU formatted as \"OLD-XXX-YYYY\" to the new SKU format \"NEW-YYYY-XXX\".', created_at=1731220624006, created_by='eric.peter@databricks.com', data_type=<ColumnTypeName.STRING: 'STRING'>, external_language='Python', external_name=None, full_data_type='STRING', full_name='ep.cookbook_local_test.translate_sku', function_id='1b81035a-035c-4cd9-b92f-78e97b953b40', input_params=FunctionParameterInfos(parameters=[FunctionParameterInfo(name='old_sku', type_text='string', type_name=<ColumnTypeName.STRING: 'STRING'>, position=0, comment='The old SKU in the format \"OLD-XXX-YYYY\".', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"old_sku\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"comment\":\"The old SKU in the format \\\\\"OLD-XXX-YYYY\\\\\".\"}}', type_precision=0, type_scale=0)]), is_deterministic=False, is_null_call=None, metastore_id='19a85dee-54bc-43a2-87ab-023d0ec16013', name='translate_sku', owner='eric.peter@databricks.com', parameter_style=<FunctionInfoParameterStyle.S: 'S'>, properties='{\"sqlConfig.spark.sql.legacy.createHiveTableByDefault\":\"false\",\"sqlConfig.spark.sql.streaming.stopTimeout\":\"15s\",\"sqlConfig.spark.sql.sources.default\":\"delta\",\"sqlConfig.spark.sql.hive.convertCTAS\":\"true\",\"sqlConfig.spark.sql.sources.commitProtocolClass\":\"com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol\",\"sqlConfig.spark.sql.parquet.compression.codec\":\"snappy\"}', return_params=None, routine_body=<FunctionInfoRoutineBody.EXTERNAL: 'EXTERNAL'>, routine_definition='\\n    import re\\n\\n    if not isinstance(old_sku, str):\\n        raise ValueError(\"SKU must be a string\")\\n\\n    # Normalize input by removing extra whitespace and converting to uppercase\\n    old_sku = old_sku.strip().upper()\\n\\n    # Define the regex pattern for the old SKU format\\n    pattern = r\"^OLD-([A-Z]{3})-(\\\\d{4})$\"\\n\\n    # Match the old SKU against the pattern\\n    match = re.match(pattern, old_sku)\\n    if not match:\\n        if not old_sku.startswith(\"OLD-\"):\\n            raise ValueError(\"SKU must start with \\'OLD-\\'\")\\n        if not re.match(r\"^OLD-[A-Z]{3}-\\\\d{4}$\", old_sku):\\n            raise ValueError(\\n                \"SKU format must be \\'OLD-XXX-YYYY\\' where X is a letter and Y is a digit\"\\n            )\\n        raise ValueError(\"Invalid SKU format\")\\n\\n    # Extract the letter code and numeric part\\n    letter_code, numeric_part = match.groups()\\n\\n    # Additional validation for numeric part\\n    if not (1 <= int(numeric_part) <= 9999):\\n        raise ValueError(\"Numeric part must be between 0001 and 9999\")\\n\\n    # Construct the new SKU\\n    new_sku = f\"NEW-{numeric_part}-{letter_code}\"\\n    return new_sku\\n', routine_dependencies=None, schema_name='cookbook_local_test', security_type=<FunctionInfoSecurityType.DEFINER: 'DEFINER'>, specific_name='translate_sku', sql_data_access=<FunctionInfoSqlDataAccess.NO_SQL: 'NO_SQL'>, sql_path=None, updated_at=1731220624006, updated_by='eric.peter@databricks.com')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.sku_translator import translate_sku\n",
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "CATALOG = \"ep\"  # Change me!\n",
    "SCHEMA = \"cookbook_local_test\"  # Change me if you want\n",
    "client.create_python_function(func=translate_sku, catalog=CATALOG, schema=SCHEMA, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job aborted due to stage failure: Task 0 in stage 434.0 failed 4 times, most recent failure: Lost task 0.3 in stage 434.0 (TID 3133) (ip-10-68-129-107.us-west-2.compute.internal executor driver): org.apache.spark.SparkRuntimeException: [UDF_USER_CODE_ERROR.GENERIC] Execution of function ep.cookbook_local_test.translate_sku(NEW-ABC-1234) failed. \\n== Error ==\\nValueError: SKU must start with \\'OLD-\\'\\n== Stacktrace ==\\n  File \"<udfbody>\", line 17, in main\\n    raise ValueError(\"SKU must start with \\'OLD-\\'\") SQLSTATE: 39000\\n== SQL (line 1, position 8) ==\\nSELECT `ep`.`cookbook_local_test`.`translate_sku`(\\'NEW-ABC-1234\\')\\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\tat com.databricks.sql.execution.safespark.SafesparkErrorMessages$.createSparkRuntimeException(SafesparkErrorMessages.scala:131)\\n\\tat com.databricks.sql.execution.safespark.SafesparkErrorMessages$.convertToSparkRuntimeException(SafesparkErrorMessages.scala:84)\\n\\tat com.databricks.sql.execution.safespark.ExternalUDFRunner$$anon$2.onError(ExternalUDFRunner.scala:486)\\n\\tat com.databricks.spark.safespark.udf.UDFSession$_TransformerProxy.onError(UDFSession.scala:131)\\n\\tat grpc_shaded.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:481)\\n\\tat grpc_shaded.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:574)\\n\\tat grpc_shaded.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:72)\\n\\tat grpc_shaded.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:742)\\n\\tat grpc_shaded.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:723)\\n\\tat grpc_shaded.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\\n\\tat grpc_shaded.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n\\nDriver stacktrace:\\n\\nJVM stacktrace:\\norg.apache.spark.SparkException\\n\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:3990)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:3909)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:3896)\\n\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\n\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:3896)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1762)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1745)\\n\\tat scala.Option.foreach(Option.scala:407)\\n\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1745)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:4248)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:4150)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:4136)\\n\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:55)\\nCaused by: org.apache.spark.SparkRuntimeException: [UDF_USER_CODE_ERROR.GENERIC] Execution of function ep.cookbook_local_test.translate_sku(NEW-ABC-1234) failed. \\n== Error ==\\nValueError: SKU must start with \\'OLD-\\'\\n== Stacktrace ==\\n  File \"<udfbody>\", line 17, in main\\n    raise ValueError(\"SKU must start with \\'OLD-\\'\") SQLSTATE: 39000\\n== SQL (line 1, position 8) ==\\nSELECT `ep`.`cookbook_local_test`.`translate_sku`(\\'NEW-ABC-1234\\')\\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\tat com.databricks.sql.execution.safespark.SafesparkErrorMessages$.createSparkRuntimeException(SafesparkErrorMessages.scala:131)\\n\\tat com.databricks.sql.execution.safespark.SafesparkErrorMessages$.convertToSparkRuntimeException(SafesparkErrorMessages.scala:84)\\n\\tat com.databricks.sql.execution.safespark.ExternalUDFRunner$$anon$2.onError(ExternalUDFRunner.scala:486)\\n\\tat com.databricks.spark.safespark.udf.UDFSession$_TransformerProxy.onError(UDFSession.scala:131)\\n\\tat grpc_shaded.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:481)\\n\\tat grpc_shaded.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:574)\\n\\tat grpc_shaded.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:72)\\n\\tat grpc_shaded.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:742)\\n\\tat grpc_shaded.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:723)\\n\\tat grpc_shaded.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\\n\\tat grpc_shaded.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\tat java.lang.Thread.run(Thread.java:750)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cookbook.tools.uc_tool import UCTool\n",
    "\n",
    "translate_sku_tool = UCTool(uc_function_name=\"ep.cookbook_local_test.translate_sku\")\n",
    "# translate_sku_tool(old_sku=\"OLD-XXX-1234\")\n",
    "\n",
    "translate_sku_tool(old_sku=\"NEW-ABC-1234\")['error']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'old_sku': {'description': 'The old SKU in the format \"OLD-XXX-YYYY\".',\n",
       "   'title': 'Old Sku',\n",
       "   'type': 'string'}},\n",
       " 'required': ['old_sku'],\n",
       " 'title': 'Translate_SkuInputs',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.sku_translator import translate_sku\n",
    "from cookbook.config import serializable_config_to_yaml_file\n",
    "\n",
    "# translate_sku(\"OLD-XXX-1234\")\n",
    "\n",
    "from cookbook.tools.local_function import LocalFunctionTool\n",
    "from tools.sku_translator import translate_sku\n",
    "\n",
    "translate_sku_tool = LocalFunctionTool(func=translate_sku, name=\"xxx\", description=\"Translates a pre-2024 SKU formatted as 'OLD-XXX-YYYY' to the new SKU format 'NEW-YYYY-XXX'.\")\n",
    "translate_sku_tool.model_dump()\n",
    "\n",
    "# translate_sku_tool._input_schema\n",
    "\n",
    "# translate_sku_tool(old_sku=\"OLD-XXX-1234\")\n",
    "\n",
    "serializable_config_to_yaml_file(translate_sku_tool, \"./configs/local_fun.yaml\")\n",
    "\n",
    "translate_sku_tool._get_parameters_schema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'xxx',\n",
       " 'description': \"Translates a pre-2024 SKU formatted as 'OLD-XXX-YYYY' to the new SKU format 'NEW-YYYY-XXX'.\",\n",
       " 'func_path': 'tools.sku_translator.translate_sku',\n",
       " 'class_path': 'cookbook.tools.local_function.LocalFunctionTool'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cookbook.config import load_serializable_config_from_yaml_file, serializable_config_to_yaml_file\n",
    "test = load_serializable_config_from_yaml_file(\"./configs/local_fun.yaml\")\n",
    "test.model_dump()\n",
    "# test._get_parameters_schema()\n",
    "# serializable_config_to_yaml_file(test, \"./configs/\"+MULTI_AGENT_DEFAULT_YAML_CONFIG_FILE_NAME+\"_loaded.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tools.sku_translator.translate_sku(old_sku: str) -> str>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "test = importlib.import_module(\"tools.sku_translator\")\n",
    "getattr(test, \"translate_sku\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tools.sku_translator.translate_sku'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.sku_translator import translate_sku\n",
    "\n",
    "translate_sku(\"OLD-XXX-1234\")\n",
    "\n",
    "from cookbook.tools.local_function import LocalFunctionTool\n",
    "from tools.sku_translator import translate_sku\n",
    "\n",
    "translate_sku_tool = LocalFunctionTool(func=translate_sku, name=\"translate_sku\", description=\"Translates a pre-2024 SKU formatted as 'OLD-XXX-YYYY' to the new SKU format 'NEW-YYYY-XXX'.\")\n",
    "translate_sku_tool.model_dump()\n",
    "\n",
    "f\"{translate_sku.__module__}.{translate_sku.__name__}\"\n",
    "\n",
    "import importlib.util\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Construct the full path to the module file\n",
    "module_path = os.path.join(cwd, \"tools\", \"sku_translator.py\")\n",
    "\n",
    "# Create the spec\n",
    "spec = importlib.util.spec_from_file_location(\"sku_translator\", module_path)\n",
    "\n",
    "# Create the module\n",
    "sku_translator = importlib.util.module_from_spec(spec)\n",
    "\n",
    "# Execute the module\n",
    "spec.loader.exec_module(sku_translator)\n",
    "\n",
    "# Get the translate_sku function\n",
    "translate_sku = sku_translator.translate_sku\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate_sku'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_name, func_name = \"tools.sku_translator.translate_sku\".rsplit(\".\", 1)\n",
    "\n",
    "func_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"tools\": [\n",
      "        {\n",
      "            \"class_path\": \"cookbook.tools.vector_search.VectorSearchRetrieverTool\",\n",
      "            \"description\": \"Use this tool to search for product documentation.\",\n",
      "            \"doc_similarity_threshold\": 0.0,\n",
      "            \"filterable_columns\": [],\n",
      "            \"name\": \"search_product_docs\",\n",
      "            \"retriever_filter_parameter_prompt\": \"optional filters to apply to the search. An array of objects, each specifying a field name and the filters to apply to that field.\",\n",
      "            \"retriever_query_parameter_prompt\": \"query to look up in retriever\",\n",
      "            \"vector_search_index\": \"ep.cookbook_local_test.product_docs_docs_chunked_index__v1\",\n",
      "            \"vector_search_parameters\": {\n",
      "                \"num_results\": 5,\n",
      "                \"query_type\": \"ann\"\n",
      "            },\n",
      "            \"vector_search_schema\": {\n",
      "                \"additional_metadata_columns\": [],\n",
      "                \"chunk_text\": \"content_chunked\",\n",
      "                \"document_uri\": \"doc_uri\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"class_path\": \"cookbook.tools.uc_tool.UCTool\",\n",
      "            \"error_prompt\": \"Error in generated code.  Please think step-by-step about how to fix the error and try calling this tool again with corrected inputs that reflect this thinking.\",\n",
      "            \"uc_function_name\": \"ep.cookbook_local_test.translate_sku\"\n",
      "        }\n",
      "    ],\n",
      "    \"llm_config\": {\n",
      "        \"llm_endpoint_name\": \"ep-gpt4o-new\",\n",
      "        \"llm_system_prompt_template\": \"## Role\\nYou are a helpful assistant that answers questions using a set of tools. If needed, you ask the user follow-up questions to clarify their request.\\n\\n## Objective\\nYour goal is to provide accurate, relevant, and helpful response based solely on the outputs from these tools. You are concise and direct in your responses.\\n\\n## Instructions\\n1. **Understand the Query**: Think step by step to analyze the user's question and determine the core need or problem. \\n\\n2. **Assess available tools**: Think step by step to consider each available tool and understand their capabilities in the context of the user's query.\\n\\n3. **Select the appropriate tool(s) OR ask follow up questions**: Based on your understanding of the query and the tool descriptions, decide which tool(s) should be used to generate a response. If you do not have enough information to use the available tools to answer the question, ask the user follow up questions to refine their request.  If you do not have a relevant tool for a question or the outputs of the tools are not helpful, respond with: \\\"I'm sorry, I can't help you with that.\\\"\",\n",
      "        \"llm_parameters\": {\n",
      "            \"temperature\": 0.01,\n",
      "            \"max_tokens\": 1500\n",
      "        }\n",
      "    },\n",
      "    \"input_example\": {\n",
      "        \"messages\": [\n",
      "            {\n",
      "                \"role\": \"user\",\n",
      "                \"content\": \"What can you help me with?\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"class_path\": \"cookbook.config.agents.function_calling_agent.FunctionCallingAgentConfig\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Import Cookbook Agent configurations, which are Pydantic models\n",
    "from cookbook.config import serializable_config_to_yaml_file\n",
    "from cookbook.config.agents.function_calling_agent import (\n",
    "    FunctionCallingAgentConfig,\n",
    ")\n",
    "from cookbook.config.data_pipeline import (\n",
    "    DataPipelineConfig,\n",
    ")\n",
    "from cookbook.config.shared.llm import LLMConfig, LLMParametersConfig\n",
    "from cookbook.config import load_serializable_config_from_yaml_file\n",
    "from cookbook.tools.vector_search import (\n",
    "    VectorSearchRetrieverTool,\n",
    "    VectorSearchSchema,\n",
    ")\n",
    "import json\n",
    "from cookbook.tools.uc_tool import UCTool\n",
    "\n",
    "\n",
    "########################\n",
    "# #### üö´‚úèÔ∏è Load the Vector Index Unity Cataloglocation from the data pipeline configuration\n",
    "# Usage:\n",
    "# - If you used `01_data_pipeline` to create your Vector Index, run this cell.\n",
    "# - If your Vector Index was created elsewhere, comment out this logic and set the UC location in the Retriever config.\n",
    "########################\n",
    "\n",
    "data_pipeline_config: DataPipelineConfig = load_serializable_config_from_yaml_file(\n",
    "    \"./configs/data_pipeline_config.yaml\"\n",
    ")\n",
    "\n",
    "########################\n",
    "# #### ‚úÖ‚úèÔ∏è Retriever tool that connects to the Vector Search index\n",
    "########################\n",
    "\n",
    "retriever_tool = VectorSearchRetrieverTool(\n",
    "    name=\"search_product_docs\",\n",
    "    description=\"Use this tool to search for product documentation.\",\n",
    "    vector_search_index=data_pipeline_config.output.vector_index,\n",
    "    vector_search_schema=VectorSearchSchema(\n",
    "        # These columns are the default values used in the `01_data_pipeline` notebook\n",
    "        # If you used a different column names in that notebook OR you are using a pre-built vector index, update the column names here.\n",
    "        chunk_text=\"content_chunked\",  # Contains the text of each document chunk\n",
    "        document_uri=\"doc_uri\",  # The document URI of the chunk e.g., \"/Volumes/catalog/schema/volume/file.pdf\" - displayed as the document ID in the Review App\n",
    "        additional_metadata_columns=[],  # Additional columns to return from the vector database and present to the LLM\n",
    "    ),\n",
    "    # Optional parameters, see VectorSearchRetrieverTool.__doc__ for details.  The default values are shown below.\n",
    "    # doc_similarity_threshold=0.0,\n",
    "    # vector_search_parameters=VectorSearchParameters(\n",
    "    #     num_results=5,\n",
    "    #     query_type=\"ann\"\n",
    "    # ),\n",
    "    # Adding columns here will allow the Agent's LLM to dynamically apply filters based on the user's query.\n",
    "    # filterable_columns=[]\n",
    ")\n",
    "\n",
    "########################\n",
    "# #### ‚úÖ‚úèÔ∏è Add Unity Catalog tools to the Agent\n",
    "########################\n",
    "\n",
    "translate_sku_tool = UCTool(uc_function_name=\"ep.cookbook_local_test.translate_sku\")\n",
    "\n",
    "from cookbook.tools.local_function import LocalFunctionTool\n",
    "from tools.sku_translator import translate_sku\n",
    "\n",
    "########################\n",
    "#### ‚úÖ‚úèÔ∏è Agent's LLM configuration\n",
    "########################\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "## Role\n",
    "You are a helpful assistant that answers questions using a set of tools. If needed, you ask the user follow-up questions to clarify their request.\n",
    "\n",
    "## Objective\n",
    "Your goal is to provide accurate, relevant, and helpful response based solely on the outputs from these tools. You are concise and direct in your responses.\n",
    "\n",
    "## Instructions\n",
    "1. **Understand the Query**: Think step by step to analyze the user's question and determine the core need or problem. \n",
    "\n",
    "2. **Assess available tools**: Think step by step to consider each available tool and understand their capabilities in the context of the user's query.\n",
    "\n",
    "3. **Select the appropriate tool(s) OR ask follow up questions**: Based on your understanding of the query and the tool descriptions, decide which tool(s) should be used to generate a response. If you do not have enough information to use the available tools to answer the question, ask the user follow up questions to refine their request.  If you do not have a relevant tool for a question or the outputs of the tools are not helpful, respond with: \"I'm sorry, I can't help you with that.\"\n",
    "\"\"\".strip()\n",
    "\n",
    "fc_agent_config = FunctionCallingAgentConfig(\n",
    "    llm_config=LLMConfig(\n",
    "        llm_endpoint_name=\"ep-gpt4o-new\",  # Model serving endpoint w/ a Chat Completions API\n",
    "        llm_system_prompt_template=system_prompt,  # System prompt template\n",
    "        llm_parameters=LLMParametersConfig(\n",
    "            temperature=0.01, max_tokens=1500\n",
    "        ),  # LLM parameters\n",
    "    ),\n",
    "    # Add one or more tools that comply with the CookbookTool interface\n",
    "    tools=[retriever_tool, translate_sku_tool],\n",
    ")\n",
    "\n",
    "# Print the configuration as a JSON string to see it all together\n",
    "print(json.dumps(fc_agent_config.model_dump(), indent=4))\n",
    "\n",
    "########################\n",
    "##### Dump the configuration to a YAML\n",
    "# Optional step, this allows the Agent's code file to be run by itself (e.g., outside of this notebook) using the above configuration.\n",
    "########################\n",
    "# Import the default YAML config file name from the Agent's code file\n",
    "from cookbook.agents.function_calling_agent import FC_AGENT_DEFAULT_YAML_CONFIG_FILE_NAME\n",
    "\n",
    "# Dump the configuration to a YAML file\n",
    "serializable_config_to_yaml_file(fc_agent_config, \"./configs/\"+FC_AGENT_DEFAULT_YAML_CONFIG_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ‚úèÔ∏è Optionally, adjust the Agent's code\n",
    "\n",
    "Here, we import the Agent's code so we can run the Agent locally within the notebook.  To modify the code, open the Agent's code file in a separate window, enable reload, make your changes, and re-run this cell.\n",
    "\n",
    "**Typically, when building the first version of your agent, we suggest first trying to tune the configuration (prompts, etc) to improve quality.  If you need more control to fix quality issues, you can then modify the Agent's code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class FunctionCallingAgent(mlflow.pyfunc.PythonModel):\n",
      "    \"\"\"\n",
      "    Class representing an Agent that does function-calling with tools using OpenAI SDK\n",
      "    \"\"\"\n",
      "\n",
      "    def load_context(self, context: PythonModelContext):\n",
      "        # If context is not None, we are in the serving environment\n",
      "        if context is not None:\n",
      "            logging.info(\n",
      "                f\"load_context received context.model_config: {context.model_config}\"\n",
      "            )\n",
      "            # we intentioanlly don't catch any errors here so the full logs show in model serving logs\n",
      "            model_config_as_yaml = yaml.dump(context.model_config)\n",
      "            self.agent_config = load_serializable_config_from_yaml(model_config_as_yaml)\n",
      "            logging.info(\n",
      "                f\"Loaded config from context.model_config: {self.agent_config}\"\n",
      "            )\n",
      "\n",
      "            if self.agent_config is None:\n",
      "                # we failed, so let's try with mlflow.ModelConfig._read_config()\n",
      "                model_config_as_yaml = yaml.dump(\n",
      "                    mlflow.models.ModelConfig()._read_config()\n",
      "                )\n",
      "                self.agent_config = load_serializable_config_from_yaml(\n",
      "                    model_config_as_yaml\n",
      "                )\n",
      "                logging.info(\n",
      "                    f\"Loaded config from mlflow.models.ModelConfig(): {self.agent_config}\"\n",
      "                )\n",
      "\n",
      "        # Now, the config will be loaded - either by above (in serving), or by __init__ (in local dev)\n",
      "        w = WorkspaceClient()\n",
      "        self.model_serving_client = w.serving_endpoints.get_open_ai_client()\n",
      "\n",
      "        # Initialize the tools\n",
      "        self.tool_functions = {}\n",
      "        self.tool_json_schemas = []\n",
      "        for tool in self.agent_config.tools:\n",
      "            self.tool_functions[tool.name] = tool\n",
      "            self.tool_json_schemas.append(tool.get_json_schema())\n",
      "\n",
      "        # Initialize the chat history to empty\n",
      "        self.chat_history = []\n",
      "\n",
      "    def __init__(\n",
      "        self, agent_config: Optional[Union[FunctionCallingAgentConfig, str]] = None\n",
      "    ):\n",
      "        super().__init__()\n",
      "        # Empty variables that will be initialized in load_context\n",
      "        self.model_serving_client = None\n",
      "        self.tool_functions = None\n",
      "        self.tool_json_schemas = None\n",
      "        self.chat_history = None\n",
      "\n",
      "        # Load the agent config if it is provided as a parameter\n",
      "        # This will only happen in the local dev environment, in serving, load_context will load the config from the mlflow.ModelConfig.\n",
      "        print(agent_config)\n",
      "        if \"agent_config\" in locals() and agent_config is not None:\n",
      "            self.agent_config = load_config(\n",
      "                agent_config=agent_config,\n",
      "                default_config_file_name=FC_AGENT_DEFAULT_YAML_CONFIG_FILE_NAME,\n",
      "            )\n",
      "            if not self.agent_config:\n",
      "                raise ValueError(\n",
      "                    f\"No agent config found.  If you are in your local development environment, make sure you either [1] are calling init(agent_config=...) with either an instance of FunctionCallingAgentConfig or the full path to a YAML config file or [2] have a YAML config file saved at ./configs/{FC_AGENT_DEFAULT_YAML_CONFIG_FILE_NAME}.\"\n",
      "                )\n",
      "            else:\n",
      "                logging.info(\n",
      "                    \"Successfully loaded agent config in __init__.  This will only happen in your local development environment.  In serving, the config will be loaded from mlflow.ModelConfig.\"\n",
      "                )\n",
      "                logging.info(f\"Loaded config: {self.agent_config.model_dump()}\")\n",
      "                # Now, call load_context to initialize the rest of the Agent\n",
      "                # HACK: We pass in None so the load_context method knows we are in the local dev environment and not serving\n",
      "                self.load_context(context=None)\n",
      "\n",
      "    @mlflow.trace(name=\"agent\", span_type=\"AGENT\")\n",
      "    def predict(\n",
      "        self,\n",
      "        context: Any = None,\n",
      "        model_input: Union[ChatCompletionRequest, Dict, pd.DataFrame] = None,\n",
      "        params: Any = None,\n",
      "    ) -> StringResponse:\n",
      "        ##############################################################################\n",
      "        # Extract `messages` key from the `model_input`\n",
      "        messages = get_messages_array(model_input)\n",
      "\n",
      "        ##############################################################################\n",
      "        # Parse `messages` array into the user's query & the chat history\n",
      "        with mlflow.start_span(name=\"parse_input\", span_type=\"PARSER\") as span:\n",
      "            span.set_inputs({\"messages\": messages})\n",
      "            user_query = extract_user_query_string(messages)\n",
      "            # Save the history inside the Agent's internal state\n",
      "            self.chat_history = extract_chat_history(messages)\n",
      "            span.set_outputs(\n",
      "                {\"user_query\": user_query, \"chat_history\": self.chat_history}\n",
      "            )\n",
      "\n",
      "        ##############################################################################\n",
      "        # Call LLM\n",
      "\n",
      "        # messages to send the model\n",
      "        # For models with shorter context length, you will need to trim this to ensure it fits within the model's context length\n",
      "        system_prompt = self.agent_config.llm_config.llm_system_prompt_template\n",
      "        messages = (\n",
      "            [{\"role\": \"system\", \"content\": system_prompt}]\n",
      "            + self.chat_history  # append chat history for multi turn\n",
      "            + [{\"role\": \"user\", \"content\": user_query}]\n",
      "        )\n",
      "\n",
      "        # Call the LLM to recursively calls tools and eventually deliver a generation to send back to the user\n",
      "        (\n",
      "            model_response,\n",
      "            messages_log_with_tool_calls,\n",
      "        ) = self.recursively_call_and_run_tools(messages=messages)\n",
      "\n",
      "        # If your front end keeps of converastion history and automatically appends the bot's response to the messages history, remove this line.\n",
      "        messages_log_with_tool_calls.append(\n",
      "            model_response.choices[0].message.to_dict()\n",
      "        )  # OpenAI client\n",
      "\n",
      "        # remove the system prompt - this should not be exposed to the Agent caller\n",
      "        messages_log_with_tool_calls = messages_log_with_tool_calls[1:]\n",
      "\n",
      "        return {\n",
      "            \"content\": model_response.choices[0].message.content,\n",
      "            # messages should be returned back to the Review App (or any other front end app) and stored there so it can be passed back to this stateless agent with the next turns of converastion.\n",
      "            \"messages\": messages_log_with_tool_calls,\n",
      "        }\n",
      "\n",
      "    @mlflow.trace(span_type=\"AGENT\")\n",
      "    def recursively_call_and_run_tools(self, max_iter=10, **kwargs):\n",
      "        messages = kwargs[\"messages\"]\n",
      "        del kwargs[\"messages\"]\n",
      "        i = 0\n",
      "        while i < max_iter:\n",
      "            response = self.chat_completion(messages=messages, tools=True)\n",
      "            assistant_message = response.choices[0].message  # openai client\n",
      "            # assistant_message = response.choices[0][\"message\"] #mlflow client\n",
      "            tool_calls = assistant_message.tool_calls  # openai\n",
      "            # tool_calls = assistant_message.get('tool_calls')#mlflow client\n",
      "            if tool_calls is None:\n",
      "                # the tool execution finished, and we have a generation\n",
      "                return (response, messages)\n",
      "            tool_messages = []\n",
      "            for tool_call in tool_calls:  # TODO: should run in parallel\n",
      "                function = tool_call.function  # openai\n",
      "                args = json.loads(function.arguments)  # openai\n",
      "                # args = json.loads(function['arguments']) #mlflow\n",
      "                # result = exec_uc_func(uc_func_name, **args)\n",
      "                # result = self.execute_function(function.name, args)  # openai\n",
      "                result = execute_function(self.tool_functions[function.name], args)\n",
      "\n",
      "                # result = self.execute_function(function['name'], args) #mlflow\n",
      "\n",
      "                # format for the LLM, will throw exception if not possible\n",
      "                # try:\n",
      "                #     result_for_llm = json.dumps(result)\n",
      "                # except Exception as e:\n",
      "                #     result_for_llm = str(result)\n",
      "\n",
      "                tool_message = {\n",
      "                    \"role\": \"tool\",\n",
      "                    \"tool_call_id\": tool_call.id,\n",
      "                    \"content\": result,\n",
      "                }  # openai\n",
      "\n",
      "                tool_messages.append(tool_message)\n",
      "            assistant_message_dict = assistant_message.dict().copy()  # openai\n",
      "            # assistant_message_dict = assistant_message.copy() #mlflow\n",
      "            del assistant_message_dict[\"content\"]\n",
      "            del assistant_message_dict[\"function_call\"]  # openai only\n",
      "            if \"audio\" in assistant_message_dict:\n",
      "                del assistant_message_dict[\"audio\"]  # llama70b hack\n",
      "            messages = (\n",
      "                messages\n",
      "                + [\n",
      "                    assistant_message_dict,\n",
      "                ]\n",
      "                + tool_messages\n",
      "            )\n",
      "            i += 1\n",
      "        # TODO: Handle more gracefully\n",
      "        raise \"ERROR: max iter reached\"\n",
      "\n",
      "    def chat_completion(self, messages: List[Dict[str, str]], tools: bool = False):\n",
      "        endpoint_name = self.agent_config.llm_config.llm_endpoint_name\n",
      "        llm_options = self.agent_config.llm_config.llm_parameters.dict()\n",
      "\n",
      "        # # Trace the call to Model Serving - openai versio\n",
      "        traced_create = mlflow.trace(\n",
      "            self.model_serving_client.chat.completions.create,\n",
      "            name=\"chat_completions_api\",\n",
      "            span_type=\"CHAT_MODEL\",\n",
      "        )\n",
      "\n",
      "        if tools:\n",
      "            return traced_create(\n",
      "                model=endpoint_name,\n",
      "                messages=messages,\n",
      "                tools=self.tool_json_schemas,\n",
      "                parallel_tool_calls=False,\n",
      "                **llm_options,\n",
      "            )\n",
      "        else:\n",
      "            return traced_create(model=endpoint_name, messages=messages, **llm_options)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cookbook.agents.function_calling_agent import FunctionCallingAgent\n",
    "import inspect\n",
    "\n",
    "# Print the Agent code for inspection\n",
    "print(inspect.getsource(FunctionCallingAgent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ‚úèÔ∏è üÖ∞ Vibe check the Agent for a single query\n",
    "\n",
    "Running this cell will produce an MLflow Trace that you can use to see the Agent's outputs and understand the steps it took to produce that output.\n",
    "\n",
    "If you are running in a local IDE, browse to the MLflow Experiment page to view the Trace (link to the Experiment UI is at the top of this notebook).  If running in a Databricks Notebook, your trace will appear inline below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tools=[VectorSearchRetrieverTool(name='search_product_docs', description='Use this tool to search for product documentation.', vector_search_index='ep.cookbook_local_test.product_docs_docs_chunked_index__v1', filterable_columns=[], vector_search_schema=VectorSearchSchema(chunk_text='content_chunked', document_uri='doc_uri', additional_metadata_columns=[]), doc_similarity_threshold=0.0, vector_search_parameters=VectorSearchParameters(num_results=5, query_type='ann'), retriever_query_parameter_prompt='query to look up in retriever', retriever_filter_parameter_prompt='optional filters to apply to the search. An array of objects, each specifying a field name and the filters to apply to that field.'), UCTool(name='ep__cookbook_local_test__translate_sku', description='Translates a pre-2024 SKU formatted as \"OLD-XXX-YYYY\" to the new SKU format \"NEW-YYYY-XXX\".', uc_function_name='ep.cookbook_local_test.translate_sku', error_prompt='Error in generated code.  Please think step-by-step about how to fix the error and try calling this tool again with corrected inputs that reflect this thinking.')] llm_config=LLMConfig(llm_endpoint_name='ep-gpt4o-new', llm_system_prompt_template='## Role\\nYou are a helpful assistant that answers questions using a set of tools. If needed, you ask the user follow-up questions to clarify their request.\\n\\n## Objective\\nYour goal is to provide accurate, relevant, and helpful response based solely on the outputs from these tools. You are concise and direct in your responses.\\n\\n## Instructions\\n1. **Understand the Query**: Think step by step to analyze the user\\'s question and determine the core need or problem. \\n\\n2. **Assess available tools**: Think step by step to consider each available tool and understand their capabilities in the context of the user\\'s query.\\n\\n3. **Select the appropriate tool(s) OR ask follow up questions**: Based on your understanding of the query and the tool descriptions, decide which tool(s) should be used to generate a response. If you do not have enough information to use the available tools to answer the question, ask the user follow up questions to refine their request.  If you do not have a relevant tool for a question or the outputs of the tools are not helpful, respond with: \"I\\'m sorry, I can\\'t help you with that.\"', llm_parameters=LLMParametersConfig(temperature=0.01, max_tokens=1500)) input_example={'messages': [{'role': 'user', 'content': 'What can you help me with?'}]}\n",
      "View the MLflow Traces at https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/3916415516852775?compareRunsMode=TRACES\n",
      "Agent's final response:\n",
      "----\n",
      "It seems there is an error with the SKU format you provided. Please ensure the SKU is in the correct format \"OLD-XXX-YYYY\" and try again.\n",
      "----\n",
      "\n",
      "Agent's full message history (useful for debugging):\n",
      "----\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"Translate the sku `OLD-abs-1234` to the new format\"\n",
      "  },\n",
      "  {\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\",\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_lK7lqkJW0yHF7Ot0PT2tflfR\",\n",
      "        \"function\": {\n",
      "          \"arguments\": \"{\\\"old_sku\\\":\\\"OLD-abs-1234\\\"}\",\n",
      "          \"name\": \"ep__cookbook_local_test__translate_sku\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"tool\",\n",
      "    \"tool_call_id\": \"call_lK7lqkJW0yHF7Ot0PT2tflfR\",\n",
      "    \"content\": \"\\\"{\\\\\\\"format\\\\\\\": \\\\\\\"SCALAR\\\\\\\", \\\\\\\"value\\\\\\\": \\\\\\\"Error: Invalid SKU format\\\\\\\"}\\\"\"\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"It seems there is an error with the SKU format you provided. Please ensure the SKU is in the correct format \\\"OLD-XXX-YYYY\\\" and try again.\",\n",
      "    \"role\": \"assistant\"\n",
      "  }\n",
      "]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from cookbook.databricks_utils import get_mlflow_experiment_traces_url\n",
    "from cookbook.agents.function_calling_agent import FunctionCallingAgent\n",
    "\n",
    "# Load the Agent's code with the above configuration\n",
    "agent = FunctionCallingAgent(fc_agent_config)\n",
    "\n",
    "# Vibe check the Agent for a single query\n",
    "output = agent.predict(model_input={\"messages\": [{\"role\": \"user\", \"content\": \"How does the blender work?\"}]})\n",
    "output = agent.predict(model_input={\"messages\": [{\"role\": \"user\", \"content\": \"Translate the sku `OLD-abs-1234` to the new format\"}]})\n",
    "\n",
    "print(f\"View the MLflow Traces at {get_mlflow_experiment_traces_url(experiment_info.experiment_id)}\")\n",
    "print(f\"Agent's final response:\\n----\\n{output['content']}\\n----\")\n",
    "print()\n",
    "print(f\"Agent's full message history (useful for debugging):\\n----\\n{json.dumps(output['messages'], indent=2)}\\n----\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test a multi-turn conversation with the Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_turn = {'messages': output['messages'] + [{\"role\": \"user\", \"content\": \"How do I turn it on?\"}]}\n",
    "\n",
    "# Run the Agent again with the same input to continue the conversation\n",
    "second_turn_output = agent.predict(model_input=second_turn)\n",
    "\n",
    "print(f\"View the MLflow Traces at {get_mlflow_experiment_traces_url(experiment_info.experiment_id)}\")\n",
    "print(f\"Agent's final response:\\n----\\n{second_turn_output['content']}\\n----\")\n",
    "print()\n",
    "print(f\"Agent's full message history (useful for debugging):\\n----\\n{json.dumps(second_turn_output['messages'], indent=2)}\\n----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ‚úèÔ∏è üÖ± Evaluate the Agent using your evaluation set\n",
    "\n",
    "Note: If you do not have an evaluation set, you can create a synthetic evaluation set by using the 03_synthetic_evaluation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set = spark.table(agent_storage_config.evaluation_set_uc_table)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = log_agent_to_mlflow(fc_agent_config)\n",
    "\n",
    "    # Run the agent for these queries, using Agent evaluation to parallelize the calls\n",
    "    eval_results = mlflow.evaluate(\n",
    "        model=logged_agent_info.model_uri,  # use the MLflow logged Agent\n",
    "        data=evaluation_set,  # Evaluate the Agent for every row of the evaluation set\n",
    "        model_type=\"databricks-agent\",  # use Agent Evaluation\n",
    "    )\n",
    "\n",
    "    # Show all outputs.  Click on a row in this table to display the MLflow Trace.\n",
    "    display(eval_results.tables[\"eval_results\"])\n",
    "\n",
    "    # Click 'View Evaluation Results' to see the Agent's inputs/outputs + quality evaluation displayed in a UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Deploy a version of your Agent - either to the Review App or Production\n",
    "\n",
    "Once you have a version of your Agent that has sufficient quality, you will register the Agent's model from the MLflow Experiment into the Unity Catalog & use Agent Framework's `agents.deploy(...)` command to deploy it.  Note these steps are the same for deploying to pre-production (e.g., the [Review App](https://docs.databricks.com/en/generative-ai/agent-evaluation/human-evaluation.html#review-app-ui) or production.\n",
    "\n",
    "By the end of this step, you will have deployed a version of your Agent that you can interact with and share with your business stakeholders for feedback, even if they don't have access to your Databricks workspace:\n",
    "\n",
    "1. A production-ready scalable REST API deployed as a Model Serving endpoint that logged every request/request/MLflow Trace to a Delta Table.\n",
    "    - REST API for querying the Agent\n",
    "    - REST API for sending user feedback from your UI to the Agent\n",
    "2. Agent Evaluation's [Review App](https://docs.databricks.com/en/generative-ai/agent-evaluation/human-evaluation.html#review-app-ui) connected to these endpoints.\n",
    "3. [Mosiac AI Playground](https://docs.databricks.com/en/large-language-models/ai-playground.html) connected to these endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Deploy the last agent you logged above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Use Unity Catalog as the model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Register the Agent's model to the Unity Catalog\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=agent_storage_config.uc_model_name\n",
    ")\n",
    "\n",
    "# Deploy the model to the review app and a model serving endpoint\n",
    "agents.deploy(agent_storage_config.uc_model_name, uc_registered_model_info.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: Log the latest copy of the Agent's code/config and deploy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7408deef4ef41a7a5b3f1d999230c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd0e75f7e544cdd9381084e58a43d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'ep.cookbook_local_test.my_agent_3'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a8ff3765524e35ab59cbbacba9b8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c6048c4fbf46a3844637dfbd6b1c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "Created version '1' of model 'ep.cookbook_local_test.my_agent_3'.\n",
      "2024/11/06 20:30:34 INFO mlflow.tracking._tracking_service.client: üèÉ View run chill-wasp-396 at: https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/3916415516852775/runs/ab806dd976064400af8cb4931d5f41b5.\n",
      "2024/11/06 20:30:34 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/3916415516852775.\n"
     ]
    }
   ],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Use Unity Catalog as the model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = log_agent_to_mlflow(fc_agent_config)\n",
    "\n",
    "    # Register the Agent's model to the Unity Catalog\n",
    "    uc_registered_model_info = mlflow.register_model(\n",
    "        model_uri=logged_agent_info.model_uri, name=agent_storage_config.uc_model_name+\"_3\"\n",
    "    )\n",
    "\n",
    "# Deploy the model to the review app and a model serving endpoint\n",
    "# agents.deploy(agent_storage_config.uc_model_name, uc_registered_model_info.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs:/ab806dd976064400af8cb4931d5f41b5/agent'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_agent_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5d49062aa54c859b6dec73403ee975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: agent\n",
       "  flavor: mlflow.pyfunc.loaders.code_model\n",
       "  run_id: ab806dd976064400af8cb4931d5f41b5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "test = mlflow.pyfunc.load_model(logged_agent_info.model_uri)\n",
    "\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = test.predict({\"messages\": [{\"role\": \"user\", \"content\": \"How does the blender work?\"}]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_path': 'cookbook.config.agents.function_calling_agent.FunctionCallingAgentConfig',\n",
       " 'input_example': {'messages': [{'content': 'What can you help me with?',\n",
       "    'role': 'user'}]},\n",
       " 'llm_config': {'llm_endpoint_name': 'ep-gpt4o-new',\n",
       "  'llm_parameters': {'max_tokens': 1500, 'temperature': 0.01},\n",
       "  'llm_system_prompt_template': '## Role\\nYou are a helpful assistant that answers questions using a set of tools. If needed, you ask the user follow-up questions to clarify their request.\\n\\n## Objective\\nYour goal is to provide accurate, relevant, and helpful response based solely on the outputs from these tools. You are concise and direct in your responses.\\n\\n## Instructions\\n1. **Understand the Query**: Think step by step to analyze the user\\'s question and determine the core need or problem. \\n\\n2. **Assess available tools**: Think step by step to consider each available tool and understand their capabilities in the context of the user\\'s query.\\n\\n3. **Select the appropriate tool(s) OR ask follow up questions**: Based on your understanding of the query and the tool descriptions, decide which tool(s) should be used to generate a response. If you do not have enough information to use the available tools to answer the question, ask the user follow up questions to refine their request.  If you do not have a relevant tool for a question or the outputs of the tools are not helpful, respond with: \"I\\'m sorry, I can\\'t help you with that.\"'},\n",
       " 'tools': [{'class_path': 'cookbook.tools.vector_search.VectorSearchRetrieverTool',\n",
       "   'description': 'Use this tool to search for product documentation.',\n",
       "   'doc_similarity_threshold': 0.0,\n",
       "   'filterable_columns': [],\n",
       "   'name': 'search_product_docs',\n",
       "   'retriever_filter_parameter_prompt': 'optional filters to apply to the search. An array of objects, each specifying a field name and the filters to apply to that field.',\n",
       "   'retriever_query_parameter_prompt': 'query to look up in retriever',\n",
       "   'vector_search_index': 'ep.cookbook_local_test.product_docs_docs_chunked_index__v1',\n",
       "   'vector_search_parameters': {'num_results': 5, 'query_type': 'ann'},\n",
       "   'vector_search_schema': {'additional_metadata_columns': [],\n",
       "    'chunk_text': 'content_chunked',\n",
       "    'document_uri': 'doc_uri'}},\n",
       "  {'class_path': 'cookbook.tools.uc_tool.UCTool',\n",
       "   'error_prompt': 'Error in generated code.  Please think step-by-step about how to fix the error and try calling this tool again with corrected inputs that reflect this thinking.',\n",
       "   'uc_function_name': 'ep.cookbook_local_test.translate_sku'}]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all attributes and methods of the test object\n",
    "dir(test)\n",
    "test.model_config\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "02_agent__function_calling_mlflow_sdk",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "genai-cookbook-T2SdtsNM-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
