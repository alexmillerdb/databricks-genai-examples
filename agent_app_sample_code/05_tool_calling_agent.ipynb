{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31661828-f9bb-4fc2-a1bd-94424a27ed52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üëâ START HERE: How to use this notebook\n",
    "\n",
    "# Step 3: Build, evaluate, & deploy your Agent\n",
    "\n",
    "Use this notebook to iterate on the code and configuration of your Agent.\n",
    "\n",
    "By the end of this notebook, you will have 1+ registered versions of your Agent, each coupled with a detailed quality evaluation.\n",
    "\n",
    "Optionally, you can deploy a version of your Agent that you can interact with in the [Mosiac AI Playground](https://docs.databricks.com/en/large-language-models/ai-playground.html) and let your business stakeholders who don't have Databricks accounts interact with it & provide feedback in the [Review App](https://docs.databricks.com/en/generative-ai/agent-evaluation/human-evaluation.html#review-app-ui).\n",
    "\n",
    "\n",
    "For each version of your agent, you will have an MLflow run inside your MLflow experiment that contains:\n",
    "- Your Agent's code & config\n",
    "- Evaluation metrics for cost, quality, and latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d9f685a-fdb7-49a4-9e3a-a4a9e964d045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Important note:** Throughout this notebook, we indicate which cell's code you:\n",
    "- ‚úÖ‚úèÔ∏è should customize - these cells contain code & config with business logic that you should edit to meet your requirements & tune quality.\n",
    "- üö´‚úèÔ∏è should not customize - these cells contain boilerplate code required to load/save/execute your Agent\n",
    "\n",
    "*Cells that don't require customization still need to be run!  You CAN change these cells, but if this is the first time using this notebook, we suggest not doing so.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb4f8cc0-1797-4beb-a9f2-df21a9db79f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üö´‚úèÔ∏è Install Python libraries\n",
    "\n",
    "You do not need to modify this cell unless you need additional Python packages in your Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d4030e8-ae97-4351-bebd-9651d283578f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install -qqqq -U -r requirements.txt\n",
    "# # Restart to load the packages into the Python environment\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üö´‚úèÔ∏è Connect to Databricks\n",
    "\n",
    "If running locally in an IDE using Databricks Connect, connect the Spark client & configure MLflow to use Databricks Managed MLflow.  If this running in a Databricks Notebook, these values are already set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.utils import databricks_utils as du\n",
    "\n",
    "if not du.is_in_databricks_notebook():\n",
    "    from databricks.connect import DatabricksSession\n",
    "    import os\n",
    "\n",
    "    spark = DatabricksSession.builder.getOrCreate()\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = \"databricks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üö´‚úèÔ∏è Load the Agent's UC storage locations; set up MLflow experiment\n",
    "\n",
    "This notebook uses the UC model, MLflow Experiment, and Evaluation Set that you specified in the [Agent setup](02_agent_setup.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"uc_model_name\": \"ep.cookbook_local_test.my_agent\",\n",
      "  \"evaluation_set_uc_table\": \"ep.cookbook_local_test.my_agent_eval_set\",\n",
      "  \"mlflow_experiment_name\": \"/Users/eric.peter@databricks.com/my_agent_mlflow_experiment\",\n",
      "  \"class_path\": \"cookbook.config.shared.agent_storage_location.AgentStorageConfig\"\n",
      "}\n",
      "View the MLflow Experiment `/Users/eric.peter@databricks.com/my_agent_mlflow_experiment` at https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/3916415516852775\n"
     ]
    }
   ],
   "source": [
    "from cookbook.config.shared.agent_storage_location import AgentStorageConfig\n",
    "from cookbook.databricks_utils import get_mlflow_experiment_url\n",
    "from cookbook.config import load_serializable_config_from_yaml_file\n",
    "import mlflow \n",
    "\n",
    "# Load the Agent's storage locations\n",
    "agent_storage_config: AgentStorageConfig= load_serializable_config_from_yaml_file(\"./configs/agent_storage_config.yaml\")\n",
    "\n",
    "# Show the Agent's storage locations\n",
    "agent_storage_config.pretty_print()\n",
    "\n",
    "# set the MLflow experiment\n",
    "experiment_info = mlflow.set_experiment(agent_storage_config.mlflow_experiment_name)\n",
    "# If running in a local IDE, set the MLflow experiment name as an environment variable\n",
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = agent_storage_config.mlflow_experiment_name\n",
    "\n",
    "print(f\"View the MLflow Experiment `{agent_storage_config.mlflow_experiment_name}` at {get_mlflow_experiment_url(experiment_info.experiment_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üö´‚úèÔ∏è Helper method to log the Agent's code & config to MLflow\n",
    "\n",
    "Before we start, let's define a helper method to log the Agent's code & config to MLflow.  We will use this to log the agent's code & config to MLflow & the Unity Catalog.  It is used in evaluation & for deploying to Agent Evaluation's [Review App](https://docs.databricks.com/en/generative-ai/agent-evaluation/human-evaluation.html#review-app-ui) (a chat UI for your stakeholders to test this agent) and later, deplying the Agent to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "from mlflow.types.llm import CHAT_MODEL_INPUT_SCHEMA\n",
    "from mlflow.models.rag_signatures import StringResponse\n",
    "from cookbook.agents.utils.signatures import STRING_RESPONSE_WITH_MESSAGES\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from cookbook.agents.function_calling_agent import FunctionCallingAgent\n",
    "from cookbook.agents.function_calling_agent import FunctionCallingAgentConfig\n",
    "\n",
    "# This helper will log the Agent's code & config to an MLflow run and return the logged model's URI\n",
    "# If run from inside a mlfow.start_run() block, it will log to that run, otherwise it will log to a new run.\n",
    "# This logged Agent is ready for deployment, so if you are happy with your evaluation, it is ready to deploy!\n",
    "def log_agent_to_mlflow(agent_config: FunctionCallingAgentConfig):\n",
    "    # Get the agent's code path from the imported Agent class\n",
    "    agent_code_path = f\"{os.getcwd()}/{FunctionCallingAgent.__module__.replace('.', '/')}.py\"\n",
    "\n",
    "    # Get the pip requirements from the requirements.txt file\n",
    "    with open(\"requirements.txt\", \"r\") as file:\n",
    "        pip_requirements = [line.strip() for line in file.readlines()] + [\"pyspark\"] # manually add pyspark\n",
    "\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"agent\",\n",
    "            python_model=agent_code_path,\n",
    "            input_example=agent_config.input_example,\n",
    "            model_config=agent_config.model_dump(),\n",
    "            resources=agent_config.get_resource_dependencies(), # This allows the agents.deploy() command to securely provision credentials for the Agent's databricks resources e.g., vector index, model serving endpoints, etc\n",
    "            signature=ModelSignature(\n",
    "            inputs=CHAT_MODEL_INPUT_SCHEMA,\n",
    "            # outputs=STRING_RESPONSE_WITH_MESSAGES #TODO: replace with MLflow signature\n",
    "            outputs=StringResponse()\n",
    "        ),\n",
    "        code_paths=[os.path.join(os.getcwd(), \"cookbook\")],\n",
    "        pip_requirements=pip_requirements,\n",
    "    )\n",
    "\n",
    "    return logged_agent_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9933d05f-29fa-452e-abdc-2a02328fbe22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 1Ô∏è‚É£ Iterate on the Agent's code & config to improve quality\n",
    "\n",
    "The below cells are used to execute your inner dev loop to improve the Agent's quality.\n",
    "\n",
    "We suggest the following process:\n",
    "1. Vibe check the Agent for 5 - 10 queries to verify it works\n",
    "2. Make any necessary changes to the code/config\n",
    "3. Use Agent Evaluation to evaluate the Agent using your evaluation set, which will provide a quality assessment & identify the root causes of any quality issues\n",
    "4. Based on that evaluation, make & test changes to the code/config to improve quality\n",
    "5. üîÅ Repeat steps 3 and 4 until you are satisified with the Agent's quality\n",
    "6. Deploy the Agent to Agent Evaluation's [Review App](https://docs.databricks.com/en/generative-ai/agent-evaluation/human-evaluation.html#review-app-ui) for pre-production testing\n",
    "7. Use the following notebooks to review that feedback (optionally adding new records to your evaluation set) & identify any further quality issues\n",
    "8. üîÅ Repeat steps 3 and 4 to fix any issues identified in step 7\n",
    "9. Deploy the Agent to a production-ready REST API endpoint (using the same cells in this notebook as step 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Cookbook Agent configurations, which are Pydantic models\n",
    "from cookbook.config import serializable_config_to_yaml_file\n",
    "from cookbook.config.agents.function_calling_agent import (\n",
    "    FunctionCallingAgentConfig,\n",
    ")\n",
    "from cookbook.config.data_pipeline import (\n",
    "    DataPipelineConfig,\n",
    ")\n",
    "from cookbook.config.shared.llm import LLMConfig, LLMParametersConfig\n",
    "from cookbook.config import load_serializable_config_from_yaml_file\n",
    "from cookbook.tools.vector_search import (\n",
    "    VectorSearchRetrieverTool,\n",
    "    VectorSearchSchema,\n",
    ")\n",
    "import json\n",
    "from cookbook.tools.uc_tool import UCTool\n",
    "\n",
    "\n",
    "########################\n",
    "# #### üö´‚úèÔ∏è Load the Vector Index Unity Cataloglocation from the data pipeline configuration\n",
    "# Usage:\n",
    "# - If you used `01_data_pipeline` to create your Vector Index, run this cell.\n",
    "# - If your Vector Index was created elsewhere, comment out this logic and set the UC location in the Retriever config.\n",
    "########################\n",
    "\n",
    "data_pipeline_config: DataPipelineConfig = load_serializable_config_from_yaml_file(\n",
    "    \"./configs/data_pipeline_config.yaml\"\n",
    ")\n",
    "\n",
    "########################\n",
    "# #### ‚úÖ‚úèÔ∏è Retriever tool that connects to the Vector Search index\n",
    "########################\n",
    "\n",
    "retriever_tool = VectorSearchRetrieverTool(\n",
    "    name=\"search_product_docs\",\n",
    "    description=\"Use this tool to search for product documentation.\",\n",
    "    vector_search_index=\"ep.cookbook_local_test.product_docs_docs_chunked_index__v1\",\n",
    "    vector_search_schema=VectorSearchSchema(\n",
    "        # These columns are the default values used in the `01_data_pipeline` notebook\n",
    "        # If you used a different column names in that notebook OR you are using a pre-built vector index, update the column names here.\n",
    "        chunk_text=\"content_chunked\",  # Contains the text of each document chunk\n",
    "        document_uri=\"doc_uri\",  # The document URI of the chunk e.g., \"/Volumes/catalog/schema/volume/file.pdf\" - displayed as the document ID in the Review App\n",
    "        additional_metadata_columns=[],  # Additional columns to return from the vector database and present to the LLM\n",
    "    ),\n",
    "    # Optional parameters, see VectorSearchRetrieverTool.__doc__ for details.  The default values are shown below.\n",
    "    # doc_similarity_threshold=0.0,\n",
    "    # vector_search_parameters=VectorSearchParameters(\n",
    "    #     num_results=5,\n",
    "    #     query_type=\"ann\"\n",
    "    # ),\n",
    "    # Adding columns here will allow the Agent's LLM to dynamically apply filters based on the user's query.\n",
    "    # filterable_columns=[]\n",
    ")\n",
    "\n",
    "########################\n",
    "# #### ‚úÖ‚úèÔ∏è Add Unity Catalog tools to the Agent\n",
    "########################\n",
    "\n",
    "translate_sku_tool = UCTool(uc_function_name=\"ep.cookbook_local_test.translate_sku\")\n",
    "\n",
    "from tools.sku_translator import translate_sku\n",
    "# from cookbook.config import serializable_config_to_yaml_file\n",
    "\n",
    "# translate_sku(\"OLD-XXX-1234\")\n",
    "\n",
    "from cookbook.tools.local_function import LocalFunctionTool\n",
    "from tools.sku_translator import translate_sku\n",
    "\n",
    "# translate_sku_tool = LocalFunctionTool(func=translate_sku, description=\"Translates a pre-2024 SKU formatted as 'OLD-XXX-YYYY' to the new SKU format 'NEW-YYYY-XXX'.\")\n",
    "\n",
    "########################\n",
    "#### ‚úÖ‚úèÔ∏è Agent's LLM configuration\n",
    "########################\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "## Role\n",
    "You are a helpful assistant that answers questions using a set of tools. If needed, you ask the user follow-up questions to clarify their request.\n",
    "\n",
    "## Objective\n",
    "Your goal is to provide accurate, relevant, and helpful response based solely on the outputs from these tools. You are concise and direct in your responses.\n",
    "\n",
    "## Instructions\n",
    "1. **Understand the Query**: Think step by step to analyze the user's question and determine the core need or problem. \n",
    "\n",
    "2. **Assess available tools**: Think step by step to consider each available tool and understand their capabilities in the context of the user's query.\n",
    "\n",
    "3. **Select the appropriate tool(s) OR ask follow up questions**: Based on your understanding of the query and the tool descriptions, decide which tool(s) should be used to generate a response. If you do not have enough information to use the available tools to answer the question, ask the user follow up questions to refine their request.  If you do not have a relevant tool for a question or the outputs of the tools are not helpful, respond with: \"I'm sorry, I can't help you with that.\"\n",
    "\"\"\".strip()\n",
    "\n",
    "fc_agent_config = FunctionCallingAgentConfig(\n",
    "    llm_config=LLMConfig(\n",
    "        llm_endpoint_name=\"ep-gpt4o-new\",  # Model serving endpoint w/ a Chat Completions API\n",
    "        llm_system_prompt_template=system_prompt,  # System prompt template\n",
    "        llm_parameters=LLMParametersConfig(\n",
    "            temperature=0.01, max_tokens=1500\n",
    "        ),  # LLM parameters\n",
    "    ),\n",
    "    # Add one or more tools that comply with the CookbookTool interface\n",
    "    # tools=[retriever_tool, translate_sku_tool],\n",
    "    tools=[retriever_tool],\n",
    ")\n",
    "\n",
    "# Print the configuration as a JSON string to see it all together\n",
    "# print(json.dumps(fc_agent_config.model_dump(), indent=4))\n",
    "\n",
    "########################\n",
    "##### Dump the configuration to a YAML\n",
    "# Optional step, this allows the Agent's code file to be run by itself (e.g., outside of this notebook) using the above configuration.\n",
    "########################\n",
    "# Import the default YAML config file name from the Agent's code file\n",
    "from cookbook.agents.function_calling_agent import FC_AGENT_DEFAULT_YAML_CONFIG_FILE_NAME\n",
    "\n",
    "# Dump the configuration to a YAML file\n",
    "serializable_config_to_yaml_file(fc_agent_config, \"./configs/\"+FC_AGENT_DEFAULT_YAML_CONFIG_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ‚úèÔ∏è Optionally, adjust the Agent's code\n",
    "\n",
    "Here, we import the Agent's code so we can run the Agent locally within the notebook.  To modify the code, open the Agent's code file in a separate window, enable reload, make your changes, and re-run this cell.\n",
    "\n",
    "**Typically, when building the first version of your agent, we suggest first trying to tune the configuration (prompts, etc) to improve quality.  If you need more control to fix quality issues, you can then modify the Agent's code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class FunctionCallingAgent(mlflow.pyfunc.PythonModel):\n",
      "    \"\"\"\n",
      "    Class representing an Agent that does function-calling with tools using OpenAI SDK\n",
      "    \"\"\"\n",
      "\n",
      "    def load_context(self, context: PythonModelContext):\n",
      "        # If context is not None, we are in the serving environment\n",
      "        if context is not None:\n",
      "            logging.info(\n",
      "                f\"load_context received context.model_config: {context.model_config}\"\n",
      "            )\n",
      "            # we intentioanlly don't catch any errors here so the full logs show in model serving logs\n",
      "            model_config_as_yaml = yaml.dump(context.model_config)\n",
      "            self.agent_config = load_serializable_config_from_yaml(model_config_as_yaml)\n",
      "            logging.info(\n",
      "                f\"Loaded config from context.model_config: {self.agent_config}\"\n",
      "            )\n",
      "\n",
      "            if self.agent_config is None:\n",
      "                # we failed, so let's try with mlflow.ModelConfig._read_config()\n",
      "                model_config_as_yaml = yaml.dump(\n",
      "                    mlflow.models.ModelConfig()._read_config()\n",
      "                )\n",
      "                self.agent_config = load_serializable_config_from_yaml(\n",
      "                    model_config_as_yaml\n",
      "                )\n",
      "                logging.info(\n",
      "                    f\"Loaded config from mlflow.models.ModelConfig(): {self.agent_config}\"\n",
      "                )\n",
      "\n",
      "        # Now, the config will be loaded - either by above (in serving), or by __init__ (in local dev)\n",
      "        w = WorkspaceClient()\n",
      "        self.model_serving_client = w.serving_endpoints.get_open_ai_client()\n",
      "\n",
      "        # Initialize the tools\n",
      "        self.tool_functions = {}\n",
      "        self.tool_json_schemas = []\n",
      "        for tool in self.agent_config.tools:\n",
      "            self.tool_functions[tool.name] = tool\n",
      "            self.tool_json_schemas.append(tool.get_json_schema())\n",
      "\n",
      "        # Initialize the chat history to empty\n",
      "        self.chat_history = []\n",
      "\n",
      "    def __init__(\n",
      "        self, agent_config: Optional[Union[FunctionCallingAgentConfig, str]] = None\n",
      "    ):\n",
      "        super().__init__()\n",
      "        # Empty variables that will be initialized in load_context\n",
      "        self.model_serving_client = None\n",
      "        self.tool_functions = None\n",
      "        self.tool_json_schemas = None\n",
      "        self.chat_history = None\n",
      "\n",
      "        # If we are in the serving env or being logged by MLflow, we will load the config from the mlflow.ModelConfig\n",
      "        try:\n",
      "            model_config_as_yaml = yaml.dump(mlflow.models.ModelConfig()._read_config())\n",
      "            self.agent_config = load_serializable_config_from_yaml(model_config_as_yaml)\n",
      "            logging.info(\n",
      "                f\"Loaded config from mlflow.models.ModelConfig(): {self.agent_config}\"\n",
      "            )\n",
      "        except Exception as e:\n",
      "            logging.info(f\"Could not load config from mlflow.models.ModelConfig(): {e}\")\n",
      "\n",
      "        # Load the agent config if it is provided as a parameter, this will overwrite anything loaded above from ModelConfig, which is OK since this is for dev & user explictly told us to use this config.\n",
      "        if agent_config is not None:\n",
      "            self.agent_config = load_config(\n",
      "                agent_config=agent_config,\n",
      "                default_config_file_name=FC_AGENT_DEFAULT_YAML_CONFIG_FILE_NAME,\n",
      "            )\n",
      "            if not self.agent_config:\n",
      "                raise ValueError(\n",
      "                    f\"`{agent_config}` No agent config found.  If you are in your local development environment, make sure you either [1] are calling init(agent_config=...) with either an instance of FunctionCallingAgentConfig or the full path to a YAML config file or [2] have a YAML config file saved at ./configs/{FC_AGENT_DEFAULT_YAML_CONFIG_FILE_NAME}.\"\n",
      "                )\n",
      "            else:\n",
      "                logging.info(\n",
      "                    \"Successfully loaded agent config in __init__.  This will only happen in your local development environment.  In serving, the config will be loaded from mlflow.ModelConfig.\"\n",
      "                )\n",
      "                logging.info(f\"Loaded config: {self.agent_config.model_dump()}\")\n",
      "                # Now, call load_context to initialize the rest of the Agent\n",
      "                # HACK: We pass in None so the load_context method knows we are in the local dev environment and not serving\n",
      "                self.load_context(context=None)\n",
      "\n",
      "    @mlflow.trace(name=\"agent\", span_type=\"AGENT\")\n",
      "    def predict(\n",
      "        self,\n",
      "        context: Any = None,\n",
      "        model_input: Union[ChatCompletionRequest, Dict, pd.DataFrame] = None,\n",
      "        params: Any = None,\n",
      "    ) -> StringResponse:\n",
      "        ##############################################################################\n",
      "        # Extract `messages` key from the `model_input`\n",
      "        messages = get_messages_array(model_input)\n",
      "\n",
      "        ##############################################################################\n",
      "        # Parse `messages` array into the user's query & the chat history\n",
      "        with mlflow.start_span(name=\"parse_input\", span_type=\"PARSER\") as span:\n",
      "            span.set_inputs({\"messages\": messages})\n",
      "            # in a multi-agent setting, the last message can be from another assistant, not the user\n",
      "            last_message = extract_user_query_string(messages)\n",
      "            last_message_role = messages[-1][\"role\"]\n",
      "            # Save the history inside the Agent's internal state\n",
      "            self.chat_history = extract_chat_history(messages)\n",
      "            span.set_outputs(\n",
      "                {\n",
      "                    \"last_message\": last_message,\n",
      "                    \"chat_history\": self.chat_history,\n",
      "                    \"last_message_role\": last_message_role,\n",
      "                }\n",
      "            )\n",
      "\n",
      "        ##############################################################################\n",
      "        # Call LLM\n",
      "\n",
      "        # messages to send the model\n",
      "        # For models with shorter context length, you will need to trim this to ensure it fits within the model's context length\n",
      "        system_prompt = self.agent_config.llm_config.llm_system_prompt_template\n",
      "        messages = (\n",
      "            [{\"role\": \"system\", \"content\": system_prompt}]\n",
      "            + self.chat_history  # append chat history for multi turn\n",
      "            + [{\"role\": last_message_role, \"content\": last_message}]\n",
      "        )\n",
      "\n",
      "        # Call the LLM to recursively calls tools and eventually deliver a generation to send back to the user\n",
      "        (\n",
      "            model_response,\n",
      "            messages_log_with_tool_calls,\n",
      "        ) = self.recursively_call_and_run_tools(messages=messages)\n",
      "\n",
      "        # If your front end keeps of converastion history and automatically appends the bot's response to the messages history, remove this line.\n",
      "        messages_log_with_tool_calls.append(\n",
      "            model_response.choices[0].message.to_dict()\n",
      "        )  # OpenAI client\n",
      "\n",
      "        # remove the system prompt - this should not be exposed to the Agent caller\n",
      "        messages_log_with_tool_calls = messages_log_with_tool_calls[1:]\n",
      "\n",
      "        return {\n",
      "            \"content\": model_response.choices[0].message.content,\n",
      "            # messages should be returned back to the Review App (or any other front end app) and stored there so it can be passed back to this stateless agent with the next turns of converastion.\n",
      "            \"messages\": messages_log_with_tool_calls,\n",
      "        }\n",
      "\n",
      "    @mlflow.trace(span_type=\"AGENT\")\n",
      "    def recursively_call_and_run_tools(self, max_iter=10, **kwargs):\n",
      "        messages = kwargs[\"messages\"]\n",
      "        del kwargs[\"messages\"]\n",
      "        i = 0\n",
      "        while i < max_iter:\n",
      "            response = self.chat_completion(messages=messages, tools=True)\n",
      "            assistant_message = response.choices[0].message  # openai client\n",
      "            # assistant_message = response.choices[0][\"message\"] #mlflow client\n",
      "            tool_calls = assistant_message.tool_calls  # openai\n",
      "            # tool_calls = assistant_message.get('tool_calls')#mlflow client\n",
      "            if tool_calls is None:\n",
      "                # the tool execution finished, and we have a generation\n",
      "                return (response, messages)\n",
      "            tool_messages = []\n",
      "            for tool_call in tool_calls:  # TODO: should run in parallel\n",
      "                function = tool_call.function  # openai\n",
      "                args = json.loads(function.arguments)  # openai\n",
      "                # args = json.loads(function['arguments']) #mlflow\n",
      "                # result = exec_uc_func(uc_func_name, **args)\n",
      "                # result = self.execute_function(function.name, args)  # openai\n",
      "                result = execute_function(self.tool_functions[function.name], args)\n",
      "\n",
      "                # result = self.execute_function(function['name'], args) #mlflow\n",
      "\n",
      "                # format for the LLM, will throw exception if not possible\n",
      "                # try:\n",
      "                #     result_for_llm = json.dumps(result)\n",
      "                # except Exception as e:\n",
      "                #     result_for_llm = str(result)\n",
      "\n",
      "                tool_message = {\n",
      "                    \"role\": \"tool\",\n",
      "                    \"tool_call_id\": tool_call.id,\n",
      "                    \"content\": result,\n",
      "                }  # openai\n",
      "\n",
      "                tool_messages.append(tool_message)\n",
      "            assistant_message_dict = assistant_message.dict().copy()  # openai\n",
      "            # assistant_message_dict = assistant_message.copy() #mlflow\n",
      "            del assistant_message_dict[\"content\"]\n",
      "            del assistant_message_dict[\"function_call\"]  # openai only\n",
      "            if \"audio\" in assistant_message_dict:\n",
      "                del assistant_message_dict[\"audio\"]  # llama70b hack\n",
      "            messages = (\n",
      "                messages\n",
      "                + [\n",
      "                    assistant_message_dict,\n",
      "                ]\n",
      "                + tool_messages\n",
      "            )\n",
      "            i += 1\n",
      "        # TODO: Handle more gracefully\n",
      "        raise \"ERROR: max iter reached\"\n",
      "\n",
      "    def chat_completion(self, messages: List[Dict[str, str]], tools: bool = False):\n",
      "        endpoint_name = self.agent_config.llm_config.llm_endpoint_name\n",
      "        llm_options = self.agent_config.llm_config.llm_parameters.dict()\n",
      "\n",
      "        # # Trace the call to Model Serving - openai versio\n",
      "        traced_create = mlflow.trace(\n",
      "            self.model_serving_client.chat.completions.create,\n",
      "            name=\"chat_completions_api\",\n",
      "            span_type=\"CHAT_MODEL\",\n",
      "        )\n",
      "\n",
      "        if tools:\n",
      "            return traced_create(\n",
      "                model=endpoint_name,\n",
      "                messages=messages,\n",
      "                tools=self.tool_json_schemas,\n",
      "                parallel_tool_calls=False,\n",
      "                **llm_options,\n",
      "            )\n",
      "        else:\n",
      "            return traced_create(model=endpoint_name, messages=messages, **llm_options)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cookbook.agents.function_calling_agent import FunctionCallingAgent\n",
    "import inspect\n",
    "\n",
    "# Print the Agent code for inspection\n",
    "print(inspect.getsource(FunctionCallingAgent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ‚úèÔ∏è üÖ∞ Vibe check the Agent for a single query\n",
    "\n",
    "Running this cell will produce an MLflow Trace that you can use to see the Agent's outputs and understand the steps it took to produce that output.\n",
    "\n",
    "If you are running in a local IDE, browse to the MLflow Experiment page to view the Trace (link to the Experiment UI is at the top of this notebook).  If running in a Databricks Notebook, your trace will appear inline below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m agent \u001b[38;5;241m=\u001b[39m FunctionCallingAgent(agent_config\u001b[38;5;241m=\u001b[39mfc_agent_config)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Vibe check the Agent for a single query\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow does the blender work?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# output = agent.predict(model_input={\"messages\": [{\"role\": \"user\", \"content\": \"Translate the sku `OLD-abs-1234` to the new format\"}]})\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mView the MLflow Traces at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_mlflow_experiment_traces_url(experiment_info\u001b[38;5;241m.\u001b[39mexperiment_id)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:175\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_WrappingContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrapping_coro\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrapping_coro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:163\u001b[0m, in \u001b[0;36mtrace.<locals>._WrappingContext.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# Since the function call occurs outside the coroutine,\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# if an exception occurs, we need to throw it back in, so that\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# we return control to the coro (in particular, so that the __exit__'s\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# of start_span and OTel's use_span can execute).\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoro\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:146\u001b[0m, in \u001b[0;36mtrace.<locals>._WrappingContext._wrapping_logic\u001b[0;34m(fn, args, kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to capture inputs for function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 146\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m  \u001b[38;5;66;03m# sync/async function output to be sent here\u001b[39;00m\n\u001b[1;32m    147\u001b[0m span\u001b[38;5;241m.\u001b[39mset_outputs(result)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:176\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _WrappingContext(fn, args, kwargs) \u001b[38;5;28;01mas\u001b[39;00m wrapping_coro:\n\u001b[0;32m--> 176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapping_coro\u001b[38;5;241m.\u001b[39msend(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Github/genai-cookbook/agent_app_sample_code/cookbook/agents/function_calling_agent.py:119\u001b[0m, in \u001b[0;36mFunctionCallingAgent.predict\u001b[0;34m(self, context, model_input, params)\u001b[0m\n\u001b[1;32m    109\u001b[0m messages \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    110\u001b[0m     [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt}]\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_history  \u001b[38;5;66;03m# append chat history for multi turn\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;241m+\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: last_message_role, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: last_message}]\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Call the LLM to recursively calls tools and eventually deliver a generation to send back to the user\u001b[39;00m\n\u001b[1;32m    116\u001b[0m (\n\u001b[1;32m    117\u001b[0m     model_response,\n\u001b[1;32m    118\u001b[0m     messages_log_with_tool_calls,\n\u001b[0;32m--> 119\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursively_call_and_run_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# If your front end keeps of converastion history and automatically appends the bot's response to the messages history, remove this line.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m messages_log_with_tool_calls\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    123\u001b[0m     model_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m    124\u001b[0m )  \u001b[38;5;66;03m# OpenAI client\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:175\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_WrappingContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrapping_coro\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrapping_coro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:163\u001b[0m, in \u001b[0;36mtrace.<locals>._WrappingContext.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# Since the function call occurs outside the coroutine,\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# if an exception occurs, we need to throw it back in, so that\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# we return control to the coro (in particular, so that the __exit__'s\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# of start_span and OTel's use_span can execute).\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoro\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:146\u001b[0m, in \u001b[0;36mtrace.<locals>._WrappingContext._wrapping_logic\u001b[0;34m(fn, args, kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to capture inputs for function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 146\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m  \u001b[38;5;66;03m# sync/async function output to be sent here\u001b[39;00m\n\u001b[1;32m    147\u001b[0m span\u001b[38;5;241m.\u001b[39mset_outputs(result)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:176\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _WrappingContext(fn, args, kwargs) \u001b[38;5;28;01mas\u001b[39;00m wrapping_coro:\n\u001b[0;32m--> 176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapping_coro\u001b[38;5;241m.\u001b[39msend(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Github/genai-cookbook/agent_app_sample_code/cookbook/agents/function_calling_agent.py:141\u001b[0m, in \u001b[0;36mFunctionCallingAgent.recursively_call_and_run_tools\u001b[0;34m(self, max_iter, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m max_iter:\n\u001b[0;32m--> 141\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     assistant_message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage  \u001b[38;5;66;03m# openai client\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     tool_calls \u001b[38;5;241m=\u001b[39m assistant_message\u001b[38;5;241m.\u001b[39mtool_calls  \u001b[38;5;66;03m# openai\u001b[39;00m\n",
      "File \u001b[0;32m~/Github/genai-cookbook/agent_app_sample_code/cookbook/agents/function_calling_agent.py:187\u001b[0m, in \u001b[0;36mFunctionCallingAgent.chat_completion\u001b[0;34m(self, messages, tools)\u001b[0m\n\u001b[1;32m    180\u001b[0m traced_create \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mtrace(\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_serving_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate,\n\u001b[1;32m    182\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_completions_api\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m     span_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCHAT_MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    184\u001b[0m )\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tools:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtraced_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_json_schemas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mllm_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traced_create(model\u001b[38;5;241m=\u001b[39mendpoint_name, messages\u001b[38;5;241m=\u001b[39mmessages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mllm_options)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:175\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_WrappingContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrapping_coro\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrapping_coro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:163\u001b[0m, in \u001b[0;36mtrace.<locals>._WrappingContext.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# Since the function call occurs outside the coroutine,\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# if an exception occurs, we need to throw it back in, so that\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# we return control to the coro (in particular, so that the __exit__'s\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# of start_span and OTel's use_span can execute).\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoro\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:146\u001b[0m, in \u001b[0;36mtrace.<locals>._WrappingContext._wrapping_logic\u001b[0;34m(fn, args, kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to capture inputs for function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 146\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m  \u001b[38;5;66;03m# sync/async function output to be sent here\u001b[39;00m\n\u001b[1;32m    147\u001b[0m span\u001b[38;5;241m.\u001b[39mset_outputs(result)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/mlflow/tracing/fluent.py:176\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _WrappingContext(fn, args, kwargs) \u001b[38;5;28;01mas\u001b[39;00m wrapping_coro:\n\u001b[0;32m--> 176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapping_coro\u001b[38;5;241m.\u001b[39msend(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/openai/_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1276\u001b[0m     )\n\u001b[0;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/openai/_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/openai/_base_client.py:990\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 990\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    996\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/genai-cookbook-T2SdtsNM-py3.11/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.10/lib/python3.11/ssl.py:1295\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1294\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.10/lib/python3.11/ssl.py:1168\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from cookbook.databricks_utils import get_mlflow_experiment_traces_url\n",
    "from cookbook.agents.function_calling_agent import FunctionCallingAgent\n",
    "\n",
    "# Load the Agent's code with the above configuration\n",
    "agent = FunctionCallingAgent(agent_config=fc_agent_config)\n",
    "\n",
    "# Vibe check the Agent for a single query\n",
    "output = agent.predict(model_input={\"messages\": [{\"role\": \"user\", \"content\": \"How does the blender work?\"}]})\n",
    "# output = agent.predict(model_input={\"messages\": [{\"role\": \"user\", \"content\": \"Translate the sku `OLD-abs-1234` to the new format\"}]})\n",
    "\n",
    "print(f\"View the MLflow Traces at {get_mlflow_experiment_traces_url(experiment_info.experiment_id)}\")\n",
    "print(f\"Agent's final response:\\n----\\n{output['content']}\\n----\")\n",
    "print()\n",
    "# print(f\"Agent's full message history (useful for debugging):\\n----\\n{json.dumps(output['messages'], indent=2)}\\n----\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test a multi-turn conversation with the Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the MLflow Traces at https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/3916415516852775?compareRunsMode=TRACES\n",
      "Agent's final response:\n",
      "----\n",
      "To turn on a blender like the TurboBlend 5000, follow these steps:\n",
      "\n",
      "1. **Assembly**: Ensure that the blade assembly is securely attached to the pitcher and that the pitcher is properly placed on the motor base.\n",
      "\n",
      "2. **Power Connection**: Plug the blender into a suitable power outlet.\n",
      "\n",
      "3. **Control Panel**: Use the intuitive control panel to select your desired setting. This may involve turning a dial or pressing a button to choose a speed or preset program.\n",
      "\n",
      "4. **Start Blending**: Once the setting is selected, press the start button to begin blending.\n",
      "\n",
      "Make sure the lid is securely fastened before starting to prevent spills. If the blender doesn't start, check that the pitcher is correctly aligned and securely placed on the base.\n",
      "----\n",
      "\n",
      "Agent's full message history (useful for debugging):\n",
      "----\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"How does the blender work?\"\n",
      "  },\n",
      "  {\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\",\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_U3IPhNMmW2ZM6EqWkxMXB0zK\",\n",
      "        \"function\": {\n",
      "          \"arguments\": \"{\\\"query\\\":\\\"how does the blender work\\\"}\",\n",
      "          \"name\": \"search_product_docs\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"tool\",\n",
      "    \"tool_call_id\": \"call_U3IPhNMmW2ZM6EqWkxMXB0zK\",\n",
      "    \"content\": \"[{\\\"page_content\\\": \\\"<product_category>Home Goods</product_category>\\\\n<product_sub_category>Blender</product_sub_category>\\\\n<product_name>TurboBlend 5000</product_name>\\\\n<product_doc>### TurboBlend 5000 Blender Documentation\\\\n\\\\n#### Welcome to the TurboBlend 5000 Experience\\\\n\\\\nThe TurboBlend 5000 is crafted for those who appreciate precision and power in their kitchen appliances. With a robust 1200-watt motor and stainless steel blades, this blender offers versatility for a wide range of culinary tasks, from smoothies to soups.\\\\n\\\\n---\\\\n\\\\n#### Product Features\\\\n- **Motor Power**: 1200 watts\\\\n- **Blades**: Hardened stainless steel\\\\n- **Capacity**: 64-ounce BPA-free pitcher\\\\n- **Speed Settings**: 10 speeds including pulse\\\\n- **Programs**: Preset options for smoothies, soup, and ice crushing\\\\n- **Accessories**: To-go cups and a comprehensive recipe book\\\\n\\\\n---\\\\n\\\\n#### Getting Started\\\\n1. **Unboxing**: Carefully remove the blender and accessories from the packaging.\\\\n2. **Assembly**: Attach the blade assembly to the pitcher. Ensure it is securely fastened.\\\\n3. **Placement**: Position the pitcher on the motor base and plug the blender into a suitable power outlet.\\\\n4. **Operation**: Select your desired setting using the intuitive control panel.\\\\n\\\\n---\\\\n\\\\n#### Usage Guidelines\\\\n- **Smoothies**: For best results, place liquid ingredients first, followed by solids.\\\\n- **Soups**: Utilize the pre-set hot soup option for perfectly blended soups.\\\\n- **Ice Crushing**: Ensure stable positioning of the blender, then select the ice crush function.\\\\n- **Pulse Mode**: Use for quick bursts of power, suitable for chunky salsas or creams.\\\\n\\\\n---\\\\n\\\\n#### Maintenance and Cleaning\\\\n- **Cleaning**: Disassemble the pitcher and rinse blades immediately after use.\\\\n- **Dishwasher Safe**: All removable components (pitcher, lid, blades) are top-rack dishwasher safe.\\\\n- **Self-Cleaning Function**: Add warm water and a drop of dish soap, run on the cleaning mode.\\\\n- **Maintenance**: Inspect the power cord regularly for damage.\\\\n\\\\n---\\\\n\\\\n#### Troubleshooting\\\\n- **Blender Won't Start**: Ensure the pitcher is correctly aligned and securely placed on the base.\\\\n- **Unusual Noises**: Check for misplaced or worn-out blade assembly and tighten as needed.\\\\n- **Overheating**: Allow the motor to cool for 15 minutes if overheated.\\\\n\\\\n---\\\\n\\\\n#### Warranty and Returns\\\\n- **Warranty Period**: Two years limited warranty covering defects in material and workmanship.\\\\n- **Returns**: Contact customer support to initiate a return process if the unit is defective. Original packaging is encouraged.\\\\n\\\\n---\\\\n\\\\n#### Customer Support\\\\nFor additional support, contact us at:\\\\n- **Phone**: 1-800-555-0199\\\\n- **Email**: support@turboblend.com\\\\n- **Live Chat**: Available on our website 9 am - 5 pm (PST) Mon-Fri\\\\n\\\\n---\\\\n\\\\n#### FAQs\\\\n**Q: How can I register my product warranty?**\\\\nA: Visit our website and navigate to the warranty registration page within 30 days of purchase.\\\\n\\\\n**Q: Can I use the blender to make nut butter?**\\\\nA: Yes, use the pulse setting and ensure sufficient processing time to achieve desired consistency.\\\\n\\\\n**Q: What should I do if the appliance malfunctions mid-cycle?**\\\\nA: Unplug the blender and contact customer support for assistance.\\\\n\\\\nEnjoy seamless blending with the TurboBlend 5000, your reliable kitchen partner.</product_doc>\\\\n<product_id>44ad0352-ed4e-48f4-a6d8-7610e955c776</product_id>\\\", \\\"metadata\\\": {\\\"similarity_score\\\": 0.0021287212, \\\"doc_uri\\\": \\\"/Volumes/ep/cookbook_local_test/product_docs/44ad0352-ed4e-48f4-a6d8-7610e955c776.jsonl\\\"}, \\\"id\\\": \\\"6b63604863cdb3394d7561bb4a229156\\\"}, {\\\"page_content\\\": \\\"<product_category>Appliances</product_category>\\\\n<product_sub_category>Blender</product_sub_category>\\\\n<product_name>VitaBlend Pro X5</product_name>\\\\n<product_doc>## Product Overview\\\\nThe VitaBlend Pro X5 is a versatile blender designed for both home enthusiasts and professional chefs. It features a powerful 1500-watt motor, precision-engineered stainless steel blades, and a durable Tritan pitcher. With its sleek, compact design, the VitaBlend Pro X5 fits easily on any countertop and complements modern kitchen decor. \\\\n\\\\n### Key Features\\\\n- **Multiple Speed Settings**: Offers 10 variable speeds and a pulse function.\\\\n- **Preset Programs**: Includes 'Smoothie', 'Crush Ice', and 'Soup' settings.\\\\n- **Safety Interlock System**: Prevents operation unless the jar is properly seated.\\\\n- **Digital Interface**: Easy-to-read display with touch controls.\\\\n\\\\n## Setup and Installation\\\\n1. **Unboxing**: Carefully remove the base, jar, lid, and tamper from the packaging.\\\\n2. **Assembly**:\\\\n   - Place the jar on the base unit.\\\\n   - Ensure the lid is secure, with the tamper inserted through the lid plug if needed.\\\\n3. **Initial Cleaning**:\\\\n   - Hand wash the jar and lid with warm, soapy water.\\\\n   - Wipe the base unit with a damp cloth.\\\\n\\\\n## Operating Instructions\\\\n- **Smoothie**:\\\\n  - Add fresh fruits, yogurt, and ice to the jar.\\\\n  - Select the 'Smoothie' preset. The blender will adjust speed and duration automatically.\\\\n- **Crushing Ice**:\\\\n  - Add ice to the jar no more than halfway.\\\\n  - Press 'Crush Ice' for optimal consistency.\\\\n\\\\n## Maintenance and Cleaning\\\\n- **After Use**: Quickly rinse the jar to clear residue.\\\\n- **Deep Cleaning**:\\\\n  - Fill halfway with warm water and a drop of dish soap.\\\\n  - Pulse for 30 seconds and rinse.\\\\n- **Blade Care**: Handle blades with care as they are sharp.\\\\n\\\\n## Troubleshooting Guide\\\\n- **Blender Won't Turn On**:\\\\n  - Check power connection.\\\\n  - Ensure safety lock is engaged.\\\\n- **Inconsistent Blending**:\\\\n  - Check if ingredients are too large or too many.\\\\n\\\\n## Customer Support\\\\n- **Warranty**: The VitaBlend Pro X5 comes with a 2-year warranty.\\\\n- **Contact**: Reach us at 1-800-555-0199 or support@vitablend.com.\\\\n\\\\n## Safety Tips\\\\n- **Avoid Overfilling**: This may cause the unit to overflow or operate improperly.\\\\n- **Unplug After Use**: Always disconnect from power when cleaning or not in use.\\\\n\\\\nWith these comprehensive guidelines, making delicious smoothies, sauces, and soups has never been easier than with the VitaBlend Pro X5. Enjoy blending with confidence knowing you're backed by our reliable customer support!</product_doc>\\\\n<product_id>5fc72cf3-781c-48f7-8b7a-5edabc952d87</product_id>\\\", \\\"metadata\\\": {\\\"similarity_score\\\": 0.00206277, \\\"doc_uri\\\": \\\"/Volumes/ep/cookbook_local_test/product_docs/5fc72cf3-781c-48f7-8b7a-5edabc952d87.jsonl\\\"}, \\\"id\\\": \\\"f86eaaa3d52c8676ef4b122be5c79712\\\"}, {\\\"page_content\\\": \\\"<product_category>Home & Kitchen</product_category>\\\\n<product_sub_category>Blender</product_sub_category>\\\\n<product_name>BlendMaster Elite 4000</product_name>\\\\n<product_doc>### Product Overview\\\\n\\\\nThe **BlendMaster Elite 4000** combines power, versatility, and style to deliver a superior blending experience. Powered by a 1200-watt motor, it is capable of tackling a wide range of blending tasks from smoothies to soups and beyond.\\\\n\\\\n### Key Features\\\\n- **Three-Speed Settings**: Low, Medium, High for tailored blending.\\\\n- **Pulse Function**: Perfect for quick blending, chopping, and controlled tasks.\\\\n- **Durable Construction**: With a shatterproof 2-liter Tritan plastic jar.\\\\n- **Stainless Steel Blades**: Six angled blades designed to crush ice and puree fruits with ease.\\\\n- **Quiet Operation**: Engineered with noise reduction technology.\\\\n- **Smart LED Display**: Offers clear settings indication and timer functionality.\\\\n\\\\n### Specifications\\\\n- **Motor**: 1200 Watts\\\\n- **Dimensions**: 16 x 8 x 8 inches\\\\n- **Weight**: 8 pounds\\\\n- **Material**: BPA-free Tritan plastic jar, stainless steel blades\\\\n- **Warranty**: 2-year limited warranty\\\\n\\\\n### Setup Instructions\\\\n1. **Unboxing**: Carefully remove the blender and all components from packaging.\\\\n2. **Assembly**: Insert the blade assembly into the jar base, twist to secure.\\\\n3. **Placement**: Position the jar on the motor base, ensuring it clicks into place.\\\\n4. **Initial Cleaning**: Wipe down the motor base with a damp cloth, wash the jar, lid, and blade assembly with warm soapy water.\\\\n\\\\n### Operating Instructions\\\\n- **Basic Use**:\\\\n  1. Place ingredients into the jar.\\\\n  2. Secure the lid, ensuring the tamper opening is sealed if not in use.\\\\n  3. Select desired speed or press 'Pulse'.\\\\n  4. Use the tamper for thick mixes, inserting through the lid.\\\\n  5. Upon completion, switch off and unplug.\\\\n\\\\n- **Making a Smoothie**:\\\\n  1. Add liquid (water, milk, juice) first.\\\\n  2. Add fruits, yogurt, and other ingredients.\\\\n  3. Blend on 'Medium' for 30-45 seconds.\\\\n\\\\n### Maintenance and Cleaning\\\\n- **After Each Use**: Rinse the jar with warm water.\\\\n- **Deep Clean Per Week**: Fill the jar halfway with water and a drop of dish soap, run on 'Low' for 30 seconds.\\\\n- **Blade Care**: Handle blades with caution; use provided brush for cleaning.\\\\n\\\\n### Troubleshooting\\\\n- **Blender Won't Start**: \\\\n  - Ensure plugged in and base securely clicked in.\\\\n  - Check for tripped circuit.\\\\n\\\\n- **Unusual Noise**:\\\\n   - Check for improperly secured components.\\\\n   - Contact support if persistent.\\\\n\\\\n- **Uneven Blending**:\\\\n  - Adjust the ingredient ratio, ensuring enough liquid present.\\\\n\\\\n### Warranty and Support\\\\nFor any issues not covered above or assistance with warranty claims:\\\\n- Contact us at support@blendmaster.com or call 1-800-555-0199.\\\\n\\\\nOur goal is to ensure you get the most out of your BlendMaster Elite 4000 each time it's used!</product_doc>\\\\n<product_id>1338b91b-975f-463a-acdc-d6e2b6defe35</product_id>\\\", \\\"metadata\\\": {\\\"similarity_score\\\": 0.0020534433, \\\"doc_uri\\\": \\\"/Volumes/ep/cookbook_local_test/product_docs/1338b91b-975f-463a-acdc-d6e2b6defe35.jsonl\\\"}, \\\"id\\\": \\\"c6d6d52e50db69a1b0db75ca8a56880a\\\"}, {\\\"page_content\\\": \\\"<product_category>Kitchen Appliances</product_category>\\\\n<product_sub_category>Blender</product_sub_category>\\\\n<product_name>SuperBlend Pro 1000</product_name>\\\\n<product_doc>### SuperBlend Pro 1000 Blender\\\\n\\\\n#### Introduction\\\\nThe SuperBlend Pro 1000 Blender is the ultimate kitchen companion, designed to meet all your blending needs with ease and efficiency. Engineered with a powerful 1000-watt motor and multiple speed settings, this blender ensures precision and power in every blend.\\\\n\\\\n#### Features\\\\n- **Powerful 1000-Watt Motor**: Perfect for crushing ice, grinding nuts, and creating velvety smoothies.\\\\n- **4-Speed Settings**: Designed for different ingredients\\\\u2014from liquids to tough vegetables and ice.\\\\n- **Pulse Function**: Provides short bursts of power for precise chopping and blending tasks.\\\\n- **1.75-Liter BPA-Free Tritan Jar**: Safe for food use and resistant to scratches and stains.\\\\n- **Stainless Steel Blades**: Durable and designed to retain sharpness for consistent cutting performance.\\\\n- **Multi-Purpose Attachments**: Includes a travel cup and grinder attachment for seeds and nuts.\\\\n- **Dual Voltage Compatibility**: Works with both 110V and 220V outlets.\\\\n\\\\n#### Using Your Blender\\\\n1. **Assembly**: Place the jar on the motor base and push until it\\\\u2019s firmly in place. Ensure the lid is securely closed before starting.\\\\n2. **Operating**:\\\\n   - Select the desired speed by turning the control dial.\\\\n   - Use the pulse button for short, powerful bursts.\\\\n3. **Safety Tips**:\\\\n   - Never operate the blender without the lid.\\\\n   - Avoid overfilling the jar beyond the maximum mark.\\\\n\\\\n#### Maintenance and Care\\\\n- **Cleaning**: Detach the jar and rinse with warm, soapy water. All removable parts are dishwasher safe.\\\\n- **Storage**: Ensure all parts are dry before storing. Keep in a cool, dry place.\\\\n\\\\n#### Troubleshooting\\\\n- **Pulse Feature Not Working**: Ensure the lid is secure and press the pulse button firmly.\\\\n- **Blender Not Starting**: Check power connection and ensure jar placement is correct.\\\\n- **Unusual Noise or Vibration**: Reduce the load or ensure all parts are securely tightened.\\\\n\\\\n#### Warranty and Support\\\\nThe SuperBlend Pro 1000 comes with a 3-year warranty covering defects in motor and blades. For assistance, contact our support team via the details on our website. Be ready with your model and purchase information.\\\\n\\\\n### Conclusion\\\\nWith advanced features and user-friendly design, the SuperBlend Pro 1000 Blender is perfect for both amateur cooks and professional chefs. Its reliability, power, and ease of use make it a smart addition to any kitchen.</product_doc>\\\\n<product_id>36be1e94-9d0c-443d-96da-6d5e0335f37c</product_id>\\\", \\\"metadata\\\": {\\\"similarity_score\\\": 0.0019637502, \\\"doc_uri\\\": \\\"/Volumes/ep/cookbook_local_test/product_docs/36be1e94-9d0c-443d-96da-6d5e0335f37c.jsonl\\\"}, \\\"id\\\": \\\"3e230c0a00469cdb54bcdef70c73e17b\\\"}, {\\\"page_content\\\": \\\"<product_category>Kitchen Appliances</product_category>\\\\n<product_sub_category>Blender</product_sub_category>\\\\n<product_name>BlendMaster 4000</product_name>\\\\n<product_doc># BlendMaster 4000 Blender\\\\n\\\\n## Introduction\\\\nWelcome to the ultimate blending experience with the BlendMaster 4000! Designed for both professional chefs and home cooks, the BlendMaster 4000 offers unmatched versatility, power, and ease of use. Whether you\\\\u2019re whipping up smoothies or crafting gourmet sauces, this blender is here to elevate your culinary creations.\\\\n\\\\n## Specifications\\\\n- **Motor Power**: 1200 watts\\\\n- **Speed Settings**: Five-speed options for versatile blending\\\\n- **Pulse Function**: Yes, for short bursts of power\\\\n- **Jar Capacity**: 2 liters\\\\n- **Blade Material**: Premium Stainless Steel\\\\n- **Dishwasher Safe Parts**: Jar, lid, and blades\\\\n- **Power Compatibility**: 110V and 220V\\\\n\\\\n## Assembly and Initial Setup\\\\n### Box Contents\\\\n1. BlendMaster 4000 Base\\\\n2. 2-Liter Blending Jar\\\\n3. Stainless Steel Blade Assembly\\\\n4. Secure-Fit Lid with Pouring Spout\\\\n5. User Manual\\\\n\\\\n### Assembly Steps\\\\n1. **Place the base** on a flat, stable surface.\\\\n2. **Attach the blade assembly** securely to the bottom of the blending jar.\\\\n3. **Position the jar** onto the base, aligning the grooves, and twist clockwise until firmly locked.\\\\n4. **Secure the lid** onto the jar, ensuring the pouring spout is closed.\\\\n\\\\n### Initial Setup\\\\n- Connect the power cord to the appropriate outlet.\\\\n- Before first use, wash all removable parts with warm, soapy water.\\\\n\\\\n## Usage Instructions\\\\n### Speed Settings\\\\n1. **Low Speed (1-2)**: Ideal for mixing liquids, sauces, and soft fruits.\\\\n2. **Medium Speed (3)**: Suitable for creaming soups and sauces.\\\\n3. **High Speed (4-5)**: Perfect for crushing ice or blending frozen ingredients.\\\\n\\\\n### Pulse Function\\\\n- Use the Pulse Function for quick bursts of power for chopping nuts or making chunky salsa.\\\\n\\\\n## Care and Maintenance\\\\n### Cleaning\\\\n- **Disassemble parts**: Remove the jar, lid, and blades.\\\\n- **Dishwasher Safe**: Place these parts in the dishwasher for easy cleaning (top rack recommended).\\\\n- **Manual Cleaning**: Alternatively, wash the parts with warm, soapy water.\\\\n- **Base Wipe Down**: Unplug the base and wipe with a damp cloth.\\\\n\\\\n### Maintenance\\\\n- Regularly check the blade assembly for signs of wear and replace if necessary.\\\\n\\\\n## Troubleshooting Guide\\\\n### Common Issues\\\\n1. **Blender Not Starting**:\\\\n   - Ensure the jar is properly aligned and locked onto the base.\\\\n   - Verify the power connection.\\\\n2. **Inconsistent Blending**:\\\\n   - Check the speed setting; adjust according to ingredient type.\\\\n3. **Pulse Function Not Working**:\\\\n   - Ensure the lid is securely locked.\\\\n   - Press the button firmly until the desired consistency is reached.\\\\n\\\\n## Warranty and Support\\\\nThe BlendMaster 4000 comes with a 3-year warranty covering defects or issues with the motor and blades. For support, contact our customer service team at support@blendmaster.com.\\\\n\\\\nEmbrace the power of blending with the BlendMaster 4000\\\\u2014where culinary dreams become reality!</product_doc>\\\\n<product_id>f463a271-e9c6-4441-9cb8-de46c1df1287</product_id>\\\", \\\"metadata\\\": {\\\"similarity_score\\\": 0.0019470346, \\\"doc_uri\\\": \\\"/Volumes/ep/cookbook_local_test/product_docs/f463a271-e9c6-4441-9cb8-de46c1df1287.jsonl\\\"}, \\\"id\\\": \\\"9047cb4efa1c9ffbf3c03a53fbf2f109\\\"}]\"\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"Blenders, such as the TurboBlend 5000, work by using a powerful motor to rotate stainless steel blades at high speeds. This action creates a vortex that pulls ingredients down into the blades, effectively chopping, blending, or pureeing them. Here's a general overview of how a typical blender operates:\\n\\n1. **Motor Power**: Blenders are equipped with motors ranging from 1000 to 1500 watts, providing the necessary power to blend a variety of ingredients, from soft fruits to hard ice.\\n\\n2. **Blades**: The blades are usually made of stainless steel and are designed to be durable and sharp, capable of crushing ice and pureeing fruits.\\n\\n3. **Speed Settings**: Most blenders offer multiple speed settings and a pulse function, allowing users to adjust the blending speed according to the ingredients and desired consistency.\\n\\n4. **Preset Programs**: Some blenders come with preset programs for specific tasks like making smoothies, crushing ice, or blending soups, which automatically adjust the speed and duration.\\n\\n5. **Assembly and Operation**: To use a blender, you typically assemble the blade assembly to the pitcher, place the pitcher on the motor base, and secure the lid. You then select the desired speed or program and start the blender.\\n\\n6. **Maintenance**: After use, blenders can be cleaned by disassembling the pitcher and blades, rinsing them, or using a self-cleaning function if available. Most parts are dishwasher safe.\\n\\nBlenders are versatile kitchen appliances used for making smoothies, soups, sauces, and more, providing convenience and efficiency in food preparation.\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"How do I turn it on?\"\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"To turn on a blender like the TurboBlend 5000, follow these steps:\\n\\n1. **Assembly**: Ensure that the blade assembly is securely attached to the pitcher and that the pitcher is properly placed on the motor base.\\n\\n2. **Power Connection**: Plug the blender into a suitable power outlet.\\n\\n3. **Control Panel**: Use the intuitive control panel to select your desired setting. This may involve turning a dial or pressing a button to choose a speed or preset program.\\n\\n4. **Start Blending**: Once the setting is selected, press the start button to begin blending.\\n\\nMake sure the lid is securely fastened before starting to prevent spills. If the blender doesn't start, check that the pitcher is correctly aligned and securely placed on the base.\",\n",
      "    \"role\": \"assistant\"\n",
      "  }\n",
      "]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "second_turn = {'messages': output['messages'] + [{\"role\": \"user\", \"content\": \"How do I turn it on?\"}]}\n",
    "\n",
    "# Run the Agent again with the same input to continue the conversation\n",
    "second_turn_output = agent.predict(model_input=second_turn)\n",
    "\n",
    "print(f\"View the MLflow Traces at {get_mlflow_experiment_traces_url(experiment_info.experiment_id)}\")\n",
    "print(f\"Agent's final response:\\n----\\n{second_turn_output['content']}\\n----\")\n",
    "print()\n",
    "print(f\"Agent's full message history (useful for debugging):\\n----\\n{json.dumps(second_turn_output['messages'], indent=2)}\\n----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ‚úèÔ∏è üÖ± Evaluate the Agent using your evaluation set\n",
    "\n",
    "Note: If you do not have an evaluation set, you can create a synthetic evaluation set by using the 03_synthetic_evaluation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set = spark.table(agent_storage_config.evaluation_set_uc_table)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = log_agent_to_mlflow(fc_agent_config)\n",
    "\n",
    "    # Run the agent for these queries, using Agent evaluation to parallelize the calls\n",
    "    eval_results = mlflow.evaluate(\n",
    "        model=logged_agent_info.model_uri,  # use the MLflow logged Agent\n",
    "        data=evaluation_set,  # Evaluate the Agent for every row of the evaluation set\n",
    "        model_type=\"databricks-agent\",  # use Agent Evaluation\n",
    "    )\n",
    "\n",
    "    # Show all outputs.  Click on a row in this table to display the MLflow Trace.\n",
    "    display(eval_results.tables[\"eval_results\"])\n",
    "\n",
    "    # Click 'View Evaluation Results' to see the Agent's inputs/outputs + quality evaluation displayed in a UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Deploy a version of your Agent - either to the Review App or Production\n",
    "\n",
    "Once you have a version of your Agent that has sufficient quality, you will register the Agent's model from the MLflow Experiment into the Unity Catalog & use Agent Framework's `agents.deploy(...)` command to deploy it.  Note these steps are the same for deploying to pre-production (e.g., the [Review App](https://docs.databricks.com/en/generative-ai/agent-evaluation/human-evaluation.html#review-app-ui) or production.\n",
    "\n",
    "By the end of this step, you will have deployed a version of your Agent that you can interact with and share with your business stakeholders for feedback, even if they don't have access to your Databricks workspace:\n",
    "\n",
    "1. A production-ready scalable REST API deployed as a Model Serving endpoint that logged every request/request/MLflow Trace to a Delta Table.\n",
    "    - REST API for querying the Agent\n",
    "    - REST API for sending user feedback from your UI to the Agent\n",
    "2. Agent Evaluation's [Review App](https://docs.databricks.com/en/generative-ai/agent-evaluation/human-evaluation.html#review-app-ui) connected to these endpoints.\n",
    "3. [Mosiac AI Playground](https://docs.databricks.com/en/large-language-models/ai-playground.html) connected to these endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Deploy the last agent you logged above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Use Unity Catalog as the model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Register the Agent's model to the Unity Catalog\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=agent_storage_config.uc_model_name\n",
    ")\n",
    "\n",
    "# Deploy the model to the review app and a model serving endpoint\n",
    "agents.deploy(agent_storage_config.uc_model_name, uc_registered_model_info.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: Log the latest copy of the Agent's code/config and deploy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ce8675359645c89497f657fbfb1587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 9\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 8\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 9\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f15860e63d448f96c1a3425cc395c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'ep.cookbook_local_test.my_agent_new_test_with_only_retriever'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4cc88e52e546a5ab3769c7f3ccf4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce3e4f9c71f4730951820c40a1eb156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: us-west-2-extstaging-managed-catalog-test-bucket-1.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "Created version '1' of model 'ep.cookbook_local_test.my_agent_new_test_with_only_retriever'.\n",
      "2024/11/17 17:25:30 INFO mlflow.tracking._tracking_service.client: üèÉ View run gifted-squirrel-916 at: https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/3916415516852775/runs/dc97ba7b22634fa8b93e475ee0af75dd.\n",
      "2024/11/17 17:25:30 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/3916415516852775.\n"
     ]
    }
   ],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Use Unity Catalog as the model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = log_agent_to_mlflow(fc_agent_config)\n",
    "\n",
    "    # Register the Agent's model to the Unity Catalog\n",
    "    uc_registered_model_info = mlflow.register_model(\n",
    "        model_uri=logged_agent_info.model_uri, name=agent_storage_config.uc_model_name+\"_new_test_with_ONLY_retriever\"\n",
    "    )\n",
    "\n",
    "# Deploy the model to the review app and a model serving endpoint\n",
    "# agents.deploy(agent_storage_config.uc_model_name, uc_registered_model_info.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the logged model to test it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79583a6db624accb16bcec887186a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'content': \"I'm sorry, I can't help you with that.\",\n",
       " 'messages': [{'role': 'user', 'content': 'A test question?'},\n",
       "  {'content': \"I'm sorry, I can't help you with that.\", 'role': 'assistant'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_agent_info.model_uri)\n",
    "\n",
    "loaded_model.predict({\"messages\": [{\"role\": \"user\", \"content\": \"A test question?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534208f8755746d09f133a351eead550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: e2-dogfood-core.s3.us-west-2.amazonaws.com. Connection pool size: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a872156d9144f7995b734536baa537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 14:20:58 INFO mlflow.tracking._tracking_service.client: üèÉ View run stately-deer-17 at: https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/3916415516852775/runs/cda8ac41f45e450b8e6ccc271a61667c.\n",
      "2024/11/17 14:20:58 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/3916415516852775.\n"
     ]
    }
   ],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Use Unity Catalog as the model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = log_agent_to_mlflow(fc_agent_config)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "02_agent__function_calling_mlflow_sdk",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "genai-cookbook-T2SdtsNM-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
