# Evaluating RAG quality

The old saying "you can't manage what you can't measure" is incredibly relevant (no pun intended) in the context of any generative AI application, RAG included. In order for your generative AI application to deliver high quality, accurate responses, you **must** be able to define and measure what "quality" means for your use case.

This section deep dives into 3 critical components of evaluation:

1. [Establishing Ground Truth: Creating Evaluation Sets](#establishing-ground-truth-creating-evaluation-sets)
2. [Assessing Performance: Defining Metrics that Matter](#assessing-performance-defining-metrics-that-matter)  
3. [Enabling Measurement: Building Supporting Infrastructure](#enabling-measurement-building-supporting-infrastructure)
